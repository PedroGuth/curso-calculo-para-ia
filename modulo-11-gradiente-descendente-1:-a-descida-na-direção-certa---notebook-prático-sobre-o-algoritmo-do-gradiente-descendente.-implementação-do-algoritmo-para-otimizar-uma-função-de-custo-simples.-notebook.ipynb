{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üèîÔ∏è Gradiente Descendente 1: A Descida na Dire√ß√£o Certa\n\n## Pedro Nunes Guth - C√°lculo para IA (M√≥dulo 11/12)\n\nBora galera! Chegou a hora de colocar a m√£o na massa e implementar o algoritmo mais famoso do machine learning! Se voc√™ chegou at√© aqui, j√° estudou derivadas, gradientes e derivadas parciais. Agora √© hora de usar tudo isso para fazer o que realmente importa: **ensinar uma m√°quina a aprender!**\n\nImagina que voc√™ t√° perdido na Serra da Mantiqueira de noite e precisa descer da montanha. Como voc√™ faria? √ìbvio: sentiria com o p√© onde t√° mais √≠ngreme pra baixo e daria um passo nessa dire√ß√£o. √â exatamente isso que o Gradiente Descendente faz!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/c√°lculo-para-ia-modulo-11_img_01.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup inicial - Bora importar as bibliotecas que vamos usar!\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import seaborn as sns\n",
        "from IPython.display import HTML, display\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configura√ß√µes para deixar os gr√°ficos bonitos\n",
        "plt.style.use('seaborn-v0_8')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"üöÄ Tudo pronto para a descida! Bora descer essa montanha do erro!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§î T√°, mas o que √© Gradiente Descendente afinal?\n\nLembra dos m√≥dulos anteriores? A gente viu que:\n- **Derivadas** nos d√£o a inclina√ß√£o de uma fun√ß√£o em um ponto\n- **Gradientes** apontam na dire√ß√£o de **maior crescimento** de uma fun√ß√£o\n- **Fun√ß√µes de custo** representam o \"erro\" do nosso modelo\n\nO Gradiente Descendente √© o algoritmo que usa essas informa√ß√µes para **minimizar** uma fun√ß√£o de custo. A ideia √© simples:\n\n1. **Calcule o gradiente** (a dire√ß√£o de maior crescimento)\n2. **V√° na dire√ß√£o oposta** (para diminuir o erro)\n3. **Repita** at√© chegar no m√≠nimo\n\n### A Matem√°tica por Tr√°s (Descomplicada!)\n\nSe temos uma fun√ß√£o de custo $J(\\theta)$ que queremos minimizar, o algoritmo funciona assim:\n\n$$\\theta_{novo} = \\theta_{atual} - \\alpha \\cdot \\nabla J(\\theta_{atual})$$\n\nOnde:\n- $\\theta$ s√£o os **par√¢metros** do modelo (pesos, bias, etc.)\n- $\\alpha$ √© a **taxa de aprendizado** (o tamanho do passo)\n- $\\nabla J(\\theta)$ √© o **gradiente** da fun√ß√£o de custo\n\n**Dica do Pedro**: O sinal negativo √© o pulo do gato! O gradiente aponta \"pra cima\", mas queremos ir \"pra baixo\" para minimizar o erro!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Visualizando o Conceito: A Montanha do Erro\n\nAntes de codar, vamos visualizar o que t√° rolando. Imagina uma fun√ß√£o de custo simples como uma montanha:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar uma fun√ß√£o de custo simples: uma par√°bola\n",
        "def funcao_custo(x):\n",
        "    \"\"\"Fun√ß√£o de custo simples: (x - 3)¬≤ + 1\n",
        "    O m√≠nimo global est√° em x = 3\n",
        "    \"\"\"\n",
        "    return (x - 3)**2 + 1\n",
        "\n",
        "def derivada_custo(x):\n",
        "    \"\"\"Derivada da fun√ß√£o de custo: 2(x - 3)\n",
        "    Nos d√° a inclina√ß√£o em qualquer ponto x\n",
        "    \"\"\"\n",
        "    return 2 * (x - 3)\n",
        "\n",
        "# Criando os pontos para o gr√°fico\n",
        "x = np.linspace(-2, 8, 1000)\n",
        "y = funcao_custo(x)\n",
        "\n",
        "# Plotando a \"montanha do erro\"\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "ax.plot(x, y, 'b-', linewidth=3, label='Fun√ß√£o de Custo J(x) = (x-3)¬≤ + 1')\n",
        "ax.axvline(x=3, color='r', linestyle='--', alpha=0.7, label='M√≠nimo Global (x=3)')\n",
        "ax.scatter([3], [1], color='red', s=200, zorder=5, label='Ponto √ìtimo')\n",
        "\n",
        "# Marcando alguns pontos de exemplo\n",
        "pontos_exemplo = [0, 1.5, 4.5, 6]\n",
        "for ponto in pontos_exemplo:\n",
        "    y_ponto = funcao_custo(ponto)\n",
        "    inclinacao = derivada_custo(ponto)\n",
        "    \n",
        "    # Plotando o ponto\n",
        "    ax.scatter([ponto], [y_ponto], color='orange', s=100, zorder=4)\n",
        "    \n",
        "    # Plotando a reta tangente (mostra a dire√ß√£o do gradiente)\n",
        "    dx = 0.5\n",
        "    x_tangente = np.array([ponto - dx, ponto + dx])\n",
        "    y_tangente = y_ponto + inclinacao * (x_tangente - ponto)\n",
        "    ax.plot(x_tangente, y_tangente, 'g--', alpha=0.6, linewidth=2)\n",
        "    \n",
        "    # Seta mostrando a dire√ß√£o de descida (oposta ao gradiente)\n",
        "    direcao = -np.sign(inclinacao) * 0.3\n",
        "    ax.arrow(ponto, y_ponto + 0.5, direcao, 0, head_width=0.3, \n",
        "             head_length=0.1, fc='purple', ec='purple', linewidth=2)\n",
        "\n",
        "ax.set_xlabel('Par√¢metro Œ∏', fontsize=14)\n",
        "ax.set_ylabel('Custo J(Œ∏)', fontsize=14)\n",
        "ax.set_title('üèîÔ∏è A Montanha do Erro - Como o Gradiente Descendente Funciona', fontsize=16)\n",
        "ax.legend(fontsize=12)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üéØ Olha s√≥! As setas roxas mostram a dire√ß√£o que devemos seguir para minimizar o erro!\")\n",
        "print(\"üìê As linhas verdes s√£o as retas tangentes - elas mostram a inclina√ß√£o (gradiente) em cada ponto.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üî• Implementando o Gradiente Descendente na M√£o!\n\nAgora vem a parte mais legal! Vamos implementar o algoritmo passo a passo. Sem bibliotecas prontas - s√≥ matem√°tica pura!\n\n### Algoritmo Passo a Passo:\n\n```mermaid\ngraph TD\n    A[Inicializar Œ∏ aleatoriamente] --> B[Calcular J(Œ∏)]\n    B --> C[Calcular ‚àáJ(Œ∏)]\n    C --> D[Atualizar: Œ∏ = Œ∏ - Œ±‚àáJ(Œ∏)]\n    D --> E{Convergiu?}\n    E -->|N√£o| B\n    E -->|Sim| F[Œ∏ √≥timo encontrado!]\n```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gradiente_descendente(funcao_custo, derivada, theta_inicial, taxa_aprendizado, max_iteracoes=1000, tolerancia=1e-6):\n",
        "    \"\"\"\n",
        "    Implementa√ß√£o do Gradiente Descendente do zero!\n",
        "    \n",
        "    Par√¢metros:\n",
        "    - funcao_custo: fun√ß√£o que queremos minimizar\n",
        "    - derivada: derivada da fun√ß√£o de custo\n",
        "    - theta_inicial: ponto de partida\n",
        "    - taxa_aprendizado: tamanho do passo (Œ±)\n",
        "    - max_iteracoes: n√∫mero m√°ximo de itera√ß√µes\n",
        "    - tolerancia: crit√©rio de parada\n",
        "    \n",
        "    Retorna:\n",
        "    - theta_otimo: par√¢metro que minimiza a fun√ß√£o\n",
        "    - historico: lista com todos os valores durante a otimiza√ß√£o\n",
        "    \"\"\"\n",
        "    \n",
        "    # Inicializando\n",
        "    theta = theta_inicial\n",
        "    historico_theta = [theta]\n",
        "    historico_custo = [funcao_custo(theta)]\n",
        "    historico_gradiente = [derivada(theta)]\n",
        "    \n",
        "    print(f\"üöÄ Come√ßando a descida do ponto Œ∏ = {theta:.4f}\")\n",
        "    print(f\"üìä Custo inicial: {funcao_custo(theta):.4f}\")\n",
        "    print(f\"üìà Gradiente inicial: {derivada(theta):.4f}\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    for i in range(max_iteracoes):\n",
        "        # 1. Calcular o gradiente no ponto atual\n",
        "        gradiente_atual = derivada(theta)\n",
        "        \n",
        "        # 2. Atualizar theta na dire√ß√£o oposta ao gradiente\n",
        "        theta_novo = theta - taxa_aprendizado * gradiente_atual\n",
        "        \n",
        "        # 3. Salvar no hist√≥rico\n",
        "        historico_theta.append(theta_novo)\n",
        "        historico_custo.append(funcao_custo(theta_novo))\n",
        "        historico_gradiente.append(derivada(theta_novo))\n",
        "        \n",
        "        # 4. Verificar converg√™ncia\n",
        "        if abs(theta_novo - theta) < tolerancia:\n",
        "            print(f\"‚úÖ Convergiu na itera√ß√£o {i+1}!\")\n",
        "            break\n",
        "            \n",
        "        # 5. Mostrar progresso a cada 100 itera√ß√µes\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Itera√ß√£o {i+1}: Œ∏ = {theta_novo:.6f}, Custo = {funcao_custo(theta_novo):.6f}\")\n",
        "        \n",
        "        # 6. Atualizar theta para a pr√≥xima itera√ß√£o\n",
        "        theta = theta_novo\n",
        "    \n",
        "    print(\"=\"*50)\n",
        "    print(f\"üéØ Resultado final:\")\n",
        "    print(f\"   Œ∏ √≥timo = {theta:.6f}\")\n",
        "    print(f\"   Custo m√≠nimo = {funcao_custo(theta):.6f}\")\n",
        "    print(f\"   Gradiente final = {derivada(theta):.6f}\")\n",
        "    \n",
        "    return theta, {\n",
        "        'theta': historico_theta,\n",
        "        'custo': historico_custo,\n",
        "        'gradiente': historico_gradiente\n",
        "    }\n",
        "\n",
        "print(\"üõ†Ô∏è Fun√ß√£o do Gradiente Descendente implementada! Agora vamos test√°-la!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Testando o Algoritmo: Primeira Descida!\n\nBora testar nosso gradiente descendente com a fun√ß√£o que criamos: $J(\\theta) = (\\theta - 3)^2 + 1$\n\nSabemos que o m√≠nimo t√° em $\\theta = 3$. Ser√° que nosso algoritmo vai conseguir encontrar?\n\n**Dica do Pedro**: A taxa de aprendizado √© crucial! Muito alta e o algoritmo vai \"pular\" o m√≠nimo, muito baixa e vai demorar uma eternidade para convergir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Teste 1: Taxa de aprendizado boa (0.1)\n",
        "print(\"üéØ TESTE 1: Taxa de aprendizado = 0.1\")\n",
        "theta_otimo_1, historico_1 = gradiente_descendente(\n",
        "    funcao_custo=funcao_custo,\n",
        "    derivada=derivada_custo, \n",
        "    theta_inicial=0.0,  # Come√ßando longe do m√≠nimo\n",
        "    taxa_aprendizado=0.1,\n",
        "    max_iteracoes=1000\n",
        ")\n",
        "\n",
        "print(f\"\\nüìä N√∫mero de itera√ß√µes: {len(historico_1['theta']) - 1}\")\n",
        "print(f\"üéØ Erro do resultado: {abs(theta_otimo_1 - 3):.8f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos visualizar a descida do gradiente!\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Gr√°fico 1: Trajet√≥ria na fun√ß√£o de custo\n",
        "x_plot = np.linspace(-1, 7, 1000)\n",
        "y_plot = funcao_custo(x_plot)\n",
        "\n",
        "ax1.plot(x_plot, y_plot, 'b-', linewidth=2, label='J(Œ∏) = (Œ∏-3)¬≤ + 1')\n",
        "ax1.plot(historico_1['theta'], historico_1['custo'], 'ro-', markersize=4, \n",
        "         linewidth=2, alpha=0.7, label='Trajet√≥ria do GD')\n",
        "ax1.scatter([historico_1['theta'][0]], [historico_1['custo'][0]], \n",
        "           color='green', s=150, marker='s', label='In√≠cio', zorder=5)\n",
        "ax1.scatter([historico_1['theta'][-1]], [historico_1['custo'][-1]], \n",
        "           color='red', s=150, marker='*', label='Final', zorder=5)\n",
        "ax1.set_xlabel('Œ∏')\n",
        "ax1.set_ylabel('Custo J(Œ∏)')\n",
        "ax1.set_title('üèîÔ∏è Descida na Montanha do Erro')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Gr√°fico 2: Evolu√ß√£o do par√¢metro Œ∏\n",
        "iteracoes = range(len(historico_1['theta']))\n",
        "ax2.plot(iteracoes, historico_1['theta'], 'g-', linewidth=2, marker='o', markersize=3)\n",
        "ax2.axhline(y=3, color='r', linestyle='--', alpha=0.7, label='Œ∏ √≥timo = 3')\n",
        "ax2.set_xlabel('Itera√ß√£o')\n",
        "ax2.set_ylabel('Œ∏')\n",
        "ax2.set_title('üìà Converg√™ncia do Par√¢metro')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Gr√°fico 3: Evolu√ß√£o do custo\n",
        "ax3.plot(iteracoes, historico_1['custo'], 'purple', linewidth=2, marker='o', markersize=3)\n",
        "ax3.axhline(y=1, color='r', linestyle='--', alpha=0.7, label='Custo m√≠nimo = 1')\n",
        "ax3.set_xlabel('Itera√ß√£o')\n",
        "ax3.set_ylabel('Custo J(Œ∏)')\n",
        "ax3.set_title('üìâ Redu√ß√£o do Custo')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Gr√°fico 4: Evolu√ß√£o do gradiente\n",
        "ax4.plot(iteracoes, historico_1['gradiente'], 'orange', linewidth=2, marker='o', markersize=3)\n",
        "ax4.axhline(y=0, color='r', linestyle='--', alpha=0.7, label='Gradiente = 0')\n",
        "ax4.set_xlabel('Itera√ß√£o')\n",
        "ax4.set_ylabel('Gradiente ‚àáJ(Œ∏)')\n",
        "ax4.set_title('üß≠ Converg√™ncia do Gradiente')\n",
        "ax4.legend()\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üéâ Liiindo! Olha como o algoritmo convergiu perfeitamente!\")\n",
        "print(\"üîç Repare que quando o gradiente chega perto de zero, encontramos o m√≠nimo!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö° O Papel Crucial da Taxa de Aprendizado\n\nA taxa de aprendizado ($\\alpha$) √© como a velocidade que voc√™ desce a montanha. Muito devagar e voc√™ nunca chega, muito r√°pido e voc√™ pode passar direto pelo vale!\n\nVamos comparar diferentes taxas de aprendizado:\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/c√°lculo-para-ia-modulo-11_img_02.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando diferentes taxas de aprendizado\n",
        "taxas = [0.01, 0.1, 0.5, 1.0]\n",
        "cores = ['blue', 'green', 'orange', 'red']\n",
        "resultados = {}\n",
        "\n",
        "print(\"üß™ Testando diferentes taxas de aprendizado...\\n\")\n",
        "\n",
        "for i, taxa in enumerate(taxas):\n",
        "    print(f\"üìä Taxa de aprendizado: {taxa}\")\n",
        "    print(\"=\"*30)\n",
        "    \n",
        "    try:\n",
        "        theta_opt, hist = gradiente_descendente(\n",
        "            funcao_custo=funcao_custo,\n",
        "            derivada=derivada_custo,\n",
        "            theta_inicial=0.0,\n",
        "            taxa_aprendizado=taxa,\n",
        "            max_iteracoes=100  # Limitando para comparar\n",
        "        )\n",
        "        resultados[taxa] = hist\n",
        "    except:\n",
        "        print(f\"‚ùå Taxa {taxa} causou instabilidade!\")\n",
        "    \n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando o impacto das diferentes taxas\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Gr√°fico 1: Converg√™ncia do par√¢metro Œ∏\n",
        "for i, (taxa, hist) in enumerate(resultados.items()):\n",
        "    iteracoes = range(len(hist['theta']))\n",
        "    ax1.plot(iteracoes, hist['theta'], color=cores[i], linewidth=2, \n",
        "             marker='o', markersize=3, label=f'Œ± = {taxa}')\n",
        "\n",
        "ax1.axhline(y=3, color='black', linestyle='--', alpha=0.7, label='Œ∏ √≥timo = 3')\n",
        "ax1.set_xlabel('Itera√ß√£o')\n",
        "ax1.set_ylabel('Œ∏')\n",
        "ax1.set_title('üéØ Converg√™ncia com Diferentes Taxas de Aprendizado')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim(-1, 7)\n",
        "\n",
        "# Gr√°fico 2: Evolu√ß√£o do custo\n",
        "for i, (taxa, hist) in enumerate(resultados.items()):\n",
        "    iteracoes = range(len(hist['custo']))\n",
        "    ax2.plot(iteracoes, hist['custo'], color=cores[i], linewidth=2, \n",
        "             marker='o', markersize=3, label=f'Œ± = {taxa}')\n",
        "\n",
        "ax2.axhline(y=1, color='black', linestyle='--', alpha=0.7, label='Custo m√≠nimo = 1')\n",
        "ax2.set_xlabel('Itera√ß√£o')\n",
        "ax2.set_ylabel('Custo J(Œ∏)')\n",
        "ax2.set_title('üìâ Redu√ß√£o do Custo com Diferentes Taxas')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_yscale('log')  # Escala logar√≠tmica para ver melhor\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üîç An√°lise dos resultados:\")\n",
        "print(\"üêå Œ± = 0.01: Muito devagar, mas est√°vel\")\n",
        "print(\"‚úÖ Œ± = 0.1: Velocidade boa, converg√™ncia suave\")\n",
        "print(\"‚ö° Œ± = 0.5: Mais r√°pido, mas pode oscilar\")\n",
        "print(\"üí• Œ± = 1.0: Muito r√°pido, pode causar instabilidade\")\n",
        "\n",
        "print(\"\\n**Dica do Pedro**: Na vida real, come√ßamos com Œ± ‚âà 0.01 a 0.1 e ajustamos conforme necess√°rio!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üåç Exemplo Pr√°tico: Regress√£o Linear com Gradiente Descendente\n\nAgora vamos aplicar o gradiente descendente em um problema real: **Regress√£o Linear!** \n\nLembra da equa√ß√£o da reta? $y = mx + b$\n\nNo machine learning, escrevemos como: $\\hat{y} = \\theta_0 + \\theta_1 x$\n\nOnde:\n- $\\theta_0$ √© o intercepto (bias)\n- $\\theta_1$ √© a inclina√ß√£o (peso)\n\n### A Fun√ß√£o de Custo: Erro Quadr√°tico M√©dio (MSE)\n\n$$J(\\theta_0, \\theta_1) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})^2$$\n\n$$J(\\theta_0, \\theta_1) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\theta_0 + \\theta_1 x^{(i)} - y^{(i)})^2$$\n\n### As Derivadas Parciais:\n\n$$\\frac{\\partial J}{\\partial \\theta_0} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})$$\n\n$$\\frac{\\partial J}{\\partial \\theta_1} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)}) \\cdot x^{(i)}$$\n\n**Dica do Pedro**: Essas derivadas parciais nos dizem como cada par√¢metro afeta o erro total!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gerando dados sint√©ticos para regress√£o linear\n",
        "np.random.seed(42)  # Para resultados reproduz√≠veis\n",
        "\n",
        "# Dados verdadeiros: y = 2x + 1 + ru√≠do\n",
        "n_amostras = 100\n",
        "X = np.random.uniform(-3, 3, n_amostras)\n",
        "y_verdadeiro = 2 * X + 1  # Linha verdadeira\n",
        "ruido = np.random.normal(0, 0.5, n_amostras)\n",
        "y = y_verdadeiro + ruido\n",
        "\n",
        "print(f\"üìä Dataset criado:\")\n",
        "print(f\"   {n_amostras} amostras\")\n",
        "print(f\"   Rela√ß√£o verdadeira: y = 2x + 1\")\n",
        "print(f\"   Ru√≠do adicionado para realismo\")\n",
        "\n",
        "# Visualizando os dados\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.scatter(X, y, alpha=0.6, color='blue', s=50, label='Dados observados')\n",
        "ax.plot(X, y_verdadeiro, 'r--', linewidth=2, label='Rela√ß√£o verdadeira: y = 2x + 1')\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_title('üìà Dataset para Regress√£o Linear')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(\"üéØ Objetivo: Usar gradiente descendente para encontrar Œ∏‚ÇÄ ‚âà 1 e Œ∏‚ÇÅ ‚âà 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RegressaoLinearGD:\n",
        "    \"\"\"Regress√£o Linear implementada com Gradiente Descendente do zero!\"\"\"\n",
        "    \n",
        "    def __init__(self, taxa_aprendizado=0.01, max_iteracoes=1000, tolerancia=1e-6):\n",
        "        self.taxa_aprendizado = taxa_aprendizado\n",
        "        self.max_iteracoes = max_iteracoes\n",
        "        self.tolerancia = tolerancia\n",
        "        self.historico = {'custo': [], 'theta0': [], 'theta1': []}\n",
        "        \n",
        "    def funcao_custo(self, X, y, theta0, theta1):\n",
        "        \"\"\"Calcula o Erro Quadr√°tico M√©dio (MSE)\"\"\"\n",
        "        m = len(X)\n",
        "        predicoes = theta0 + theta1 * X\n",
        "        custo = (1/(2*m)) * np.sum((predicoes - y)**2)\n",
        "        return custo\n",
        "    \n",
        "    def calcular_gradientes(self, X, y, theta0, theta1):\n",
        "        \"\"\"Calcula as derivadas parciais\"\"\"\n",
        "        m = len(X)\n",
        "        predicoes = theta0 + theta1 * X\n",
        "        erros = predicoes - y\n",
        "        \n",
        "        # Derivadas parciais\n",
        "        d_theta0 = (1/m) * np.sum(erros)\n",
        "        d_theta1 = (1/m) * np.sum(erros * X)\n",
        "        \n",
        "        return d_theta0, d_theta1\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Treina o modelo usando Gradiente Descendente\"\"\"\n",
        "        # Inicializa√ß√£o aleat√≥ria dos par√¢metros\n",
        "        self.theta0 = np.random.normal(0, 0.1)\n",
        "        self.theta1 = np.random.normal(0, 0.1)\n",
        "        \n",
        "        print(f\"üöÄ Iniciando treinamento...\")\n",
        "        print(f\"   Par√¢metros iniciais: Œ∏‚ÇÄ = {self.theta0:.4f}, Œ∏‚ÇÅ = {self.theta1:.4f}\")\n",
        "        print(f\"   Taxa de aprendizado: {self.taxa_aprendizado}\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        for i in range(self.max_iteracoes):\n",
        "            # Calcular custo atual\n",
        "            custo_atual = self.funcao_custo(X, y, self.theta0, self.theta1)\n",
        "            \n",
        "            # Calcular gradientes\n",
        "            d_theta0, d_theta1 = self.calcular_gradientes(X, y, self.theta0, self.theta1)\n",
        "            \n",
        "            # Salvar no hist√≥rico\n",
        "            self.historico['custo'].append(custo_atual)\n",
        "            self.historico['theta0'].append(self.theta0)\n",
        "            self.historico['theta1'].append(self.theta1)\n",
        "            \n",
        "            # Atualizar par√¢metros (GRADIENTE DESCENDENTE!)\n",
        "            theta0_novo = self.theta0 - self.taxa_aprendizado * d_theta0\n",
        "            theta1_novo = self.theta1 - self.taxa_aprendizado * d_theta1\n",
        "            \n",
        "            # Verificar converg√™ncia\n",
        "            if abs(theta0_novo - self.theta0) < self.tolerancia and abs(theta1_novo - self.theta1) < self.tolerancia:\n",
        "                print(f\"‚úÖ Converg√™ncia atingida na itera√ß√£o {i+1}!\")\n",
        "                break\n",
        "                \n",
        "            # Mostrar progresso\n",
        "            if (i + 1) % 100 == 0:\n",
        "                print(f\"Itera√ß√£o {i+1}: Custo = {custo_atual:.6f}, Œ∏‚ÇÄ = {theta0_novo:.4f}, Œ∏‚ÇÅ = {theta1_novo:.4f}\")\n",
        "            \n",
        "            # Atualizar par√¢metros\n",
        "            self.theta0 = theta0_novo\n",
        "            self.theta1 = theta1_novo\n",
        "        \n",
        "        print(\"=\"*60)\n",
        "        print(f\"üéØ Treinamento conclu√≠do!\")\n",
        "        print(f\"   Œ∏‚ÇÄ (intercepto) = {self.theta0:.6f} (verdadeiro: 1.0)\")\n",
        "        print(f\"   Œ∏‚ÇÅ (inclina√ß√£o) = {self.theta1:.6f} (verdadeiro: 2.0)\")\n",
        "        print(f\"   Custo final = {self.historico['custo'][-1]:.6f}\")\n",
        "        \n",
        "    def predict(self, X):\n",
        "        \"\"\"Faz predi√ß√µes\"\"\"\n",
        "        return self.theta0 + self.theta1 * X\n",
        "\n",
        "# Criando e treinando o modelo\n",
        "modelo = RegressaoLinearGD(taxa_aprendizado=0.1, max_iteracoes=1000)\n",
        "modelo.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Visualizando o Aprendizado em A√ß√£o\n\nAgora vem a parte mais legal: ver como o modelo **aprende** durante o treinamento!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/c√°lculo-para-ia-modulo-11_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando o processo de aprendizado\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Gr√°fico 1: Evolu√ß√£o da linha de regress√£o\n",
        "ax1.scatter(X, y, alpha=0.6, color='lightblue', s=30, label='Dados')\n",
        "ax1.plot(X, y_verdadeiro, 'r--', linewidth=2, label='y = 2x + 1 (verdadeiro)')\n",
        "\n",
        "# Mostrar algumas itera√ß√µes do aprendizado\n",
        "X_plot = np.linspace(X.min(), X.max(), 100)\n",
        "iteracoes_mostrar = [0, len(modelo.historico['theta0'])//4, len(modelo.historico['theta0'])//2, -1]\n",
        "cores_linha = ['red', 'orange', 'green', 'blue']\n",
        "labels_linha = ['In√≠cio', '25%', '50%', 'Final']\n",
        "\n",
        "for i, (iter_idx, cor, label) in enumerate(zip(iteracoes_mostrar, cores_linha, labels_linha)):\n",
        "    theta0_iter = modelo.historico['theta0'][iter_idx]\n",
        "    theta1_iter = modelo.historico['theta1'][iter_idx]\n",
        "    y_pred_iter = theta0_iter + theta1_iter * X_plot\n",
        "    ax1.plot(X_plot, y_pred_iter, color=cor, linewidth=2, alpha=0.8, label=f'{label}: y = {theta1_iter:.2f}x + {theta0_iter:.2f}')\n",
        "\n",
        "ax1.set_xlabel('x')\n",
        "ax1.set_ylabel('y')\n",
        "ax1.set_title('üéØ Evolu√ß√£o da Linha de Regress√£o')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Gr√°fico 2: Converg√™ncia do custo\n",
        "iteracoes = range(len(modelo.historico['custo']))\n",
        "ax2.plot(iteracoes, modelo.historico['custo'], 'purple', linewidth=2)\n",
        "ax2.set_xlabel('Itera√ß√£o')\n",
        "ax2.set_ylabel('Custo (MSE)')\n",
        "ax2.set_title('üìâ Redu√ß√£o do Custo Durante o Treinamento')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_yscale('log')\n",
        "\n",
        "# Gr√°fico 3: Converg√™ncia dos par√¢metros\n",
        "ax3.plot(iteracoes, modelo.historico['theta0'], 'blue', linewidth=2, label='Œ∏‚ÇÄ (intercepto)')\n",
        "ax3.plot(iteracoes, modelo.historico['theta1'], 'red', linewidth=2, label='Œ∏‚ÇÅ (inclina√ß√£o)')\n",
        "ax3.axhline(y=1, color='blue', linestyle='--', alpha=0.7, label='Œ∏‚ÇÄ verdadeiro = 1')\n",
        "ax3.axhline(y=2, color='red', linestyle='--', alpha=0.7, label='Œ∏‚ÇÅ verdadeiro = 2')\n",
        "ax3.set_xlabel('Itera√ß√£o')\n",
        "ax3.set_ylabel('Valor do Par√¢metro')\n",
        "ax3.set_title('üìà Converg√™ncia dos Par√¢metros')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Gr√°fico 4: Superf√≠cie de custo 3D (conceitual)\n",
        "theta0_range = np.linspace(0, 2, 50)\n",
        "theta1_range = np.linspace(1, 3, 50)\n",
        "THETA0, THETA1 = np.meshgrid(theta0_range, theta1_range)\n",
        "\n",
        "# Calculando a superf√≠cie de custo\n",
        "CUSTO = np.zeros_like(THETA0)\n",
        "for i in range(THETA0.shape[0]):\n",
        "    for j in range(THETA0.shape[1]):\n",
        "        CUSTO[i, j] = modelo.funcao_custo(X, y, THETA0[i, j], THETA1[i, j])\n",
        "\n",
        "contour = ax4.contour(THETA0, THETA1, CUSTO, levels=20, alpha=0.6)\n",
        "ax4.clabel(contour, inline=True, fontsize=8)\n",
        "\n",
        "# Plotando a trajet√≥ria do gradiente descendente\n",
        "ax4.plot(modelo.historico['theta0'], modelo.historico['theta1'], 'ro-', \n",
        "         linewidth=2, markersize=3, alpha=0.8, label='Trajet√≥ria GD')\n",
        "ax4.scatter([modelo.historico['theta0'][0]], [modelo.historico['theta1'][0]], \n",
        "           color='green', s=100, marker='s', label='In√≠cio', zorder=5)\n",
        "ax4.scatter([modelo.historico['theta0'][-1]], [modelo.historico['theta1'][-1]], \n",
        "           color='red', s=150, marker='*', label='Final', zorder=5)\n",
        "ax4.scatter([1], [2], color='blue', s=100, marker='x', label='√ìtimo verdadeiro', zorder=5)\n",
        "\n",
        "ax4.set_xlabel('Œ∏‚ÇÄ (intercepto)')\n",
        "ax4.set_ylabel('Œ∏‚ÇÅ (inclina√ß√£o)')\n",
        "ax4.set_title('üó∫Ô∏è Trajet√≥ria na Superf√≠cie de Custo')\n",
        "ax4.legend()\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üéâ Liiindo! Olha como o gradiente descendente encontrou os par√¢metros quase perfeitamente!\")\n",
        "print(f\"üí° Erro no Œ∏‚ÇÄ: {abs(modelo.theta0 - 1):.6f}\")\n",
        "print(f\"üí° Erro no Œ∏‚ÇÅ: {abs(modelo.theta1 - 2):.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üî• Exerc√≠cio Pr√°tico 1: Sua Vez de Implementar!\n\nAgora √© sua vez! Vou dar uma fun√ß√£o de custo diferente e voc√™ vai implementar o gradiente descendente para ela.\n\n**Fun√ß√£o:** $J(\\theta) = \\theta^4 - 4\\theta^3 + 6\\theta^2 - 4\\theta + 5$\n\n**Derivada:** $J'(\\theta) = 4\\theta^3 - 12\\theta^2 + 12\\theta - 4$\n\n**Desafio:** Encontre o m√≠nimo global desta fun√ß√£o!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/c√°lculo-para-ia-modulo-11_img_04.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERC√çCIO 1: Complete as fun√ß√µes abaixo\n",
        "\n",
        "def funcao_exercicio(theta):\n",
        "    \"\"\"TODO: Implemente J(Œ∏) = Œ∏‚Å¥ - 4Œ∏¬≥ + 6Œ∏¬≤ - 4Œ∏ + 5\"\"\"\n",
        "    # Sua implementa√ß√£o aqui\n",
        "    pass\n",
        "\n",
        "def derivada_exercicio(theta):\n",
        "    \"\"\"TODO: Implemente J'(Œ∏) = 4Œ∏¬≥ - 12Œ∏¬≤ + 12Œ∏ - 4\"\"\"\n",
        "    # Sua implementa√ß√£o aqui\n",
        "    pass\n",
        "\n",
        "# TODO: Use a fun√ß√£o gradiente_descendente que criamos para encontrar o m√≠nimo\n",
        "# Teste com diferentes pontos iniciais: -1, 0, 2, 3\n",
        "# Dica: Esta fun√ß√£o tem m√∫ltiplos m√≠nimos locais!\n",
        "\n",
        "print(\"üéØ Seu desafio: encontrar o m√≠nimo global da fun√ß√£o!\")\n",
        "print(\"üí° Dica: Teste diferentes pontos iniciais para ver o que acontece!\")\n",
        "\n",
        "# Descomente as linhas abaixo quando implementar as fun√ß√µes\n",
        "# theta_otimo, historico = gradiente_descendente(\n",
        "#     funcao_custo=funcao_exercicio,\n",
        "#     derivada=derivada_exercicio,\n",
        "#     theta_inicial=0.0,  # Experimente outros valores!\n",
        "#     taxa_aprendizado=0.01,\n",
        "#     max_iteracoes=1000\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üö® Problemas Comuns no Gradiente Descendente\n\nComo toda t√©cnica poderosa, o gradiente descendente tem suas pegadinhas. Vamos ver os principais problemas:\n\n### 1. üêå M√≠nimos Locais vs M√≠nimo Global\n\nImagina que voc√™ t√° descendo uma montanha no escuro e cai num buraco. Voc√™ pode pensar que chegou no fundo, mas na verdade existe um vale muito mais profundo do lado!\n\n```mermaid\ngraph TD\n    A[Fun√ß√£o n√£o-convexa] --> B{M√∫ltiplos m√≠nimos}\n    B --> C[M√≠nimo Local 1]\n    B --> D[M√≠nimo Local 2]\n    B --> E[M√≠nimo Global]\n    C --> F[‚ùå Pode parar aqui]\n    D --> F\n    E --> G[‚úÖ Queremos chegar aqui]\n```\n\n### 2. üé¢ Taxa de Aprendizado Inadequada\n\n- **Muito baixa**: Converge muito devagar (como uma lesma subindo no pau de sebo)\n- **Muito alta**: Fica pulando de um lado pro outro sem nunca convergir (como um pintinho tonto)\n\n### 3. üèîÔ∏è Plat√¥s e Selas\n\n√Äs vezes o gradiente fica muito pequeno em regi√µes \"planas\", fazendo o algoritmo andar muito devagar.\n\n**Dica do Pedro**: Por isso surgiram vers√µes melhoradas como Adam, RMSprop, etc. (que veremos no pr√≥ximo m√≥dulo!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrando o problema dos m√≠nimos locais\n",
        "def funcao_multimodal(x):\n",
        "    \"\"\"Fun√ß√£o com m√∫ltiplos m√≠nimos locais\"\"\"\n",
        "    return x**4 - 4*x**3 + 6*x**2 - 4*x + 5\n",
        "\n",
        "def derivada_multimodal(x):\n",
        "    \"\"\"Derivada da fun√ß√£o multimodal\"\"\"\n",
        "    return 4*x**3 - 12*x**2 + 12*x - 4\n",
        "\n",
        "# Testando diferentes pontos iniciais\n",
        "pontos_iniciais = [-0.5, 0.5, 1.5, 2.5]\n",
        "resultados_multimodal = {}\n",
        "\n",
        "print(\"üß™ Testando o problema dos m√≠nimos locais...\\n\")\n",
        "\n",
        "for ponto in pontos_iniciais:\n",
        "    print(f\"üìç Ponto inicial: {ponto}\")\n",
        "    theta_opt, hist = gradiente_descendente(\n",
        "        funcao_custo=funcao_multimodal,\n",
        "        derivada=derivada_multimodal,\n",
        "        theta_inicial=ponto,\n",
        "        taxa_aprendizado=0.01,\n",
        "        max_iteracoes=500\n",
        "    )\n",
        "    resultados_multimodal[ponto] = (theta_opt, hist)\n",
        "    print(f\"üéØ Convergiu para: Œ∏ = {theta_opt:.4f}, J(Œ∏) = {funcao_multimodal(theta_opt):.4f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando o problema dos m√≠nimos locais\n",
        "x_plot = np.linspace(-1, 3, 1000)\n",
        "y_plot = funcao_multimodal(x_plot)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Gr√°fico 1: Fun√ß√£o com trajet√≥rias\n",
        "ax1.plot(x_plot, y_plot, 'b-', linewidth=3, label='J(Œ∏) = Œ∏‚Å¥ - 4Œ∏¬≥ + 6Œ∏¬≤ - 4Œ∏ + 5')\n",
        "\n",
        "cores = ['red', 'green', 'orange', 'purple']\n",
        "for i, (ponto_inicial, (theta_final, hist)) in enumerate(resultados_multimodal.items()):\n",
        "    # Trajet√≥ria\n",
        "    ax1.plot(hist['theta'], hist['custo'], 'o-', color=cores[i], \n",
        "             alpha=0.7, markersize=3, linewidth=2, \n",
        "             label=f'In√≠cio: {ponto_inicial} ‚Üí Final: {theta_final:.2f}')\n",
        "    \n",
        "    # Ponto inicial\n",
        "    ax1.scatter([ponto_inicial], [funcao_multimodal(ponto_inicial)], \n",
        "               color=cores[i], s=150, marker='s', zorder=5)\n",
        "    \n",
        "    # Ponto final\n",
        "    ax1.scatter([theta_final], [funcao_multimodal(theta_final)], \n",
        "               color=cores[i], s=200, marker='*', zorder=5)\n",
        "\n",
        "ax1.set_xlabel('Œ∏')\n",
        "ax1.set_ylabel('J(Œ∏)')\n",
        "ax1.set_title('üé¢ Problema dos M√≠nimos Locais')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Gr√°fico 2: Converg√™ncia do custo\n",
        "for i, (ponto_inicial, (theta_final, hist)) in enumerate(resultados_multimodal.items()):\n",
        "    iteracoes = range(len(hist['custo']))\n",
        "    ax2.plot(iteracoes, hist['custo'], color=cores[i], linewidth=2,\n",
        "             label=f'In√≠cio: {ponto_inicial}')\n",
        "\n",
        "ax2.set_xlabel('Itera√ß√£o')\n",
        "ax2.set_ylabel('Custo J(Œ∏)')\n",
        "ax2.set_title('üìâ Converg√™ncia para Diferentes M√≠nimos')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_yscale('log')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üîç An√°lise dos resultados:\")\n",
        "print(\"‚Ä¢ Pontos iniciais diferentes podem levar a m√≠nimos diferentes!\")\n",
        "print(\"‚Ä¢ Este √© um dos grandes desafios da otimiza√ß√£o n√£o-convexa\")\n",
        "print(\"‚Ä¢ Na pr√°tica: rodamos v√°rias vezes com inicializa√ß√µes aleat√≥rias\")\n",
        "\n",
        "print(\"\\n**Dica do Pedro**: Em redes neurais, a inicializa√ß√£o dos pesos √© super importante!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Exerc√≠cio Pr√°tico 2: Comparando Taxas de Aprendizado\n\nAgora voc√™ vai experimentar com diferentes taxas de aprendizado e ver como elas afetam a converg√™ncia.\n\n**Sua miss√£o**: Testar as taxas [0.001, 0.01, 0.1, 0.5] na fun√ß√£o do exerc√≠cio anterior e comparar:\n- Velocidade de converg√™ncia\n- Estabilidade\n- Qual chega mais perto do m√≠nimo verdadeiro\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/c√°lculo-para-ia-modulo-11_img_05.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERC√çCIO 2: Complete o c√≥digo para comparar taxas de aprendizado\n",
        "\n",
        "# TODO: Teste estas taxas de aprendizado na fun√ß√£o multimodal\n",
        "taxas_teste = [0.001, 0.01, 0.1, 0.5]\n",
        "ponto_inicial_fixo = 0.0\n",
        "\n",
        "print(\"üèÅ EXERC√çCIO: Comparando taxas de aprendizado\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# TODO: Para cada taxa, execute o gradiente descendente e compare:\n",
        "# 1. N√∫mero de itera√ß√µes at√© convergir\n",
        "# 2. Valor final do custo\n",
        "# 3. Valor final do par√¢metro Œ∏\n",
        "# 4. Estabilidade (oscila√ß√µes?)\n",
        "\n",
        "resultados_taxas = {}\n",
        "\n",
        "for taxa in taxas_teste:\n",
        "    print(f\"\\nüéØ Testando taxa = {taxa}\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    # TODO: Chame a fun√ß√£o gradiente_descendente aqui\n",
        "    # Salve os resultados em resultados_taxas[taxa]\n",
        "    \n",
        "    pass  # Remova esta linha quando implementar\n",
        "\n",
        "# TODO: Crie visualiza√ß√µes comparando os resultados\n",
        "# Dicas: \n",
        "# - Gr√°fico da converg√™ncia do custo para cada taxa\n",
        "# - Gr√°fico da converg√™ncia do par√¢metro Œ∏\n",
        "# - Tabela resumo com os resultados finais\n",
        "\n",
        "print(\"\\nüìä An√°lise: Qual taxa funcionou melhor e por qu√™?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Quando Usar Gradiente Descendente?\n\nO gradiente descendente √© o cora√ß√£o do machine learning moderno! Ele √© usado em:\n\n### ‚úÖ **Ideal para:**\n- **Redes neurais** (backpropagation √© gradiente descendente!)\n- **Regress√£o linear/log√≠stica** com muitos dados\n- **Deep learning** (√∫nica op√ß√£o vi√°vel para milh√µes de par√¢metros)\n- **Fun√ß√µes diferenci√°veis** que n√£o t√™m solu√ß√£o anal√≠tica\n\n### ‚ùå **N√£o √© ideal para:**\n- **Fun√ß√µes n√£o-diferenci√°veis** (√≥bvio!)\n- **Espa√ßos discretos** (n√£o tem \"dire√ß√£o\" para descer)\n- **Problemas pequenos** com solu√ß√£o anal√≠tica simples\n\n### üî• **Vers√µes Modernas:**\n- **SGD** (Stochastic): Usa mini-batches dos dados\n- **Adam**: Adapta a taxa de aprendizado automaticamente  \n- **RMSprop**: Lida melhor com gradientes que variam muito\n- **Momentum**: Adiciona \"in√©rcia\" para passar por m√≠nimos locais\n\n**Dica do Pedro**: No pr√≥ximo m√≥dulo vamos ver essas vers√µes turbinasdas! Prepare-se!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† Conectando com o Que Vem Pela Frente\n\nO gradiente descendente que implementamos hoje √© a vers√£o \"batch\" - usa todos os dados de uma vez. Mas e se tivermos 1 milh√£o de exemplos? Vai ser muito lento!\n\nNo **M√≥dulo 12** (√∫ltimo do curso!), vamos ver:\n\n### üöÄ **Stochastic Gradient Descent (SGD)**\nEm vez de usar todos os dados, usa apenas um exemplo por vez:\n\n$$\\theta = \\theta - \\alpha \\nabla J^{(i)}(\\theta)$$\n\n### ‚ö° **Mini-batch Gradient Descent**\nMeio termo: usa pequenos grupos de dados:\n\n$$\\theta = \\theta - \\alpha \\frac{1}{m_{batch}} \\sum_{j=1}^{m_{batch}} \\nabla J^{(j)}(\\theta)$$\n\n### üß† **Adam Optimizer**\nO mais usado hoje em deep learning - adapta a taxa de aprendizado:\n\n$$m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t$$\n$$v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2$$\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/c√°lculo-para-ia-modulo-11_img_06.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pr√©via do que vem no pr√≥ximo m√≥dulo: Mini-batch\n",
        "def mini_batch_preview(X, y, batch_size=10):\n",
        "    \"\"\"Pr√©via de como funciona o mini-batch (veremos no pr√≥ximo m√≥dulo)\"\"\"\n",
        "    \n",
        "    n_amostras = len(X)\n",
        "    indices = np.arange(n_amostras)\n",
        "    np.random.shuffle(indices)  # Embaralha os dados\n",
        "    \n",
        "    print(f\"üìä Dataset completo: {n_amostras} amostras\")\n",
        "    print(f\"üéØ Tamanho do mini-batch: {batch_size}\")\n",
        "    print(f\"üîÑ N√∫mero de mini-batches: {n_amostras // batch_size}\")\n",
        "    print(\"\\nExemplo de mini-batches:\")\n",
        "    \n",
        "    for i in range(0, min(n_amostras, 3 * batch_size), batch_size):\n",
        "        batch_indices = indices[i:i+batch_size]\n",
        "        X_batch = X[batch_indices]\n",
        "        y_batch = y[batch_indices]\n",
        "        \n",
        "        print(f\"  Mini-batch {i//batch_size + 1}: {len(X_batch)} amostras\")\n",
        "        print(f\"    X: [{X_batch[0]:.2f}, {X_batch[1]:.2f}, ..., {X_batch[-1]:.2f}]\")\n",
        "        print(f\"    y: [{y_batch[0]:.2f}, {y_batch[1]:.2f}, ..., {y_batch[-1]:.2f}]\")\n",
        "    \n",
        "    print(\"\\nüí° No pr√≥ximo m√≥dulo: cada mini-batch far√° uma atualiza√ß√£o dos par√¢metros!\")\n",
        "    print(\"üöÄ Isso torna o treinamento muito mais r√°pido e eficiente!\")\n",
        "\n",
        "# Demonstra√ß√£o\n",
        "mini_batch_preview(X, y, batch_size=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Resumo do M√≥dulo: O Que Aprendemos\n\nParab√©ns! üéâ Voc√™ acabou de dominar um dos algoritmos mais importantes do machine learning!\n\n### ‚úÖ **O que rolou neste m√≥dulo:**\n\n1. **üß≠ Entendemos o conceito**: Gradiente descendente √© como descer uma montanha seguindo a dire√ß√£o mais √≠ngreme\n\n2. **üìê A matem√°tica**: $\\theta_{novo} = \\theta_{atual} - \\alpha \\nabla J(\\theta)$\n\n3. **üíª Implementamos do zero**: Sem bibliotecas, s√≥ matem√°tica pura!\n\n4. **üéØ Aplicamos na pr√°tica**: Regress√£o linear completa com gradiente descendente\n\n5. **‚ö†Ô∏è Vimos as pegadinhas**: M√≠nimos locais, taxa de aprendizado, converg√™ncia\n\n6. **üìä Visualizamos tudo**: Gr√°ficos que mostram como o algoritmo aprende\n\n### üîë **Conceitos-chave para levar:**\n\n- O **gradiente aponta \"pra cima\"**, ent√£o vamos na **dire√ß√£o oposta** para minimizar\n- A **taxa de aprendizado** ($\\alpha$) controla o tamanho do passo\n- **Inicializa√ß√£o** importa em fun√ß√µes n√£o-convexas\n- **Converg√™ncia** acontece quando o gradiente fica pr√≥ximo de zero\n\n### üöÄ **Conectando com o curso:**\n\n- **M√≥dulos 1-3**: Prepararam o terreno (fun√ß√µes, limites)\n- **M√≥dulos 4-6**: Derivadas e regra da cadeia (base do gradiente)\n- **M√≥dulos 9-10**: M√∫ltiplas vari√°veis e gradientes (matem√°tica por tr√°s)\n- **M√≥dulo 11** (atual): Implementa√ß√£o pr√°tica do algoritmo\n- **M√≥dulo 12** (pr√≥ximo): Vers√µes avan√ßadas (SGD, Adam, etc.)\n\n**Dica do Pedro**: Agora voc√™ entende o que t√° rolando \"por baixo dos panos\" quando treina qualquer modelo de ML! Isso √© poder! üí™\n\n### üéØ **Para o pr√≥ximo m√≥dulo:**\n\nPrepare-se para ver como o gradiente descendente evoluiu para lidar com:\n- **Big Data** (milh√µes de exemplos)\n- **Deep Learning** (milh√µes de par√¢metros)  \n- **Converg√™ncia mais r√°pida** (otimizadores adaptativos)\n- **Estabilidade num√©rica** (truques dos profissionais)\n\nBora para o √∫ltimo m√≥dulo! üöÄ"
      ]
    }
  ]
}