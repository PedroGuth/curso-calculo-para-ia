{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üé¢ Derivadas 1: A Velocidade Instant√¢nea da Matem√°tica!\n## M√≥dulo 4: A Taxa de Varia√ß√£o Imediata - Como Medir a \"Pressa\" de uma Fun√ß√£o\n\nFala galera! Pedro Guth aqui! üöÄ\n\nT√°, mas o que diabos √© uma derivada afinal? Imagina que voc√™ t√° dirigindo na estrada e olha pro veloc√≠metro - ele te mostra **exatamente** a velocidade que voc√™ t√° naquele momento espec√≠fico, n√£o a velocidade m√©dia da viagem toda. A derivada √© isso: ela te diz o qu√£o \"r√°pido\" uma fun√ß√£o t√° mudando em um ponto espec√≠fico!\n\nNos m√≥dulos anteriores, a gente viu:\n- **M√≥dulo 1**: Por que c√°lculo √© importante (lembra da montanha do erro?)\n- **M√≥dulo 2**: Como visualizar fun√ß√µes\n- **M√≥dulo 3**: Limites (chegando perto sem tocar)\n\nAgora vamos conectar tudo isso e descobrir como **medir a inclina√ß√£o** de qualquer curva em qualquer ponto!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/c√°lculo-para-ia-modulo-04_img_01.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup inicial - Bora come√ßar!\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import FancyArrowPatch\n",
        "import sympy as sp\n",
        "from IPython.display import display, Markdown\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configura√ß√µes para gr√°ficos mais bonitos\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"üî• Tudo pronto! Bora entender derivadas!\")\n",
        "print(\"üìä Bibliotecas carregadas com sucesso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§î O Problema: Como Medir a \"Inclina√ß√£o\" de uma Curva?\n\n√ì, vamos pensar assim: voc√™ consegue medir a inclina√ß√£o de uma reta, n√©? √â s√≥ pegar dois pontos e fazer aquele c√°lculo b√°sico:\n\n$$\\text{Inclina√ß√£o} = \\frac{\\text{Subida}}{\\text{Corrida}} = \\frac{\\Delta y}{\\Delta x} = \\frac{y_2 - y_1}{x_2 - x_1}$$\n\nMas e se a fun√ß√£o n√£o for uma reta? E se for uma par√°bola, uma exponencial, ou nossa querida **fun√ß√£o de custo** l√° do aprendizado de m√°quina?\n\n**O problema**: Curvas n√£o t√™m inclina√ß√£o \"fixa\" - ela muda a todo momento!\n\n**A solu√ß√£o**: A derivada! Ela nos d√° a inclina√ß√£o **exata** em qualquer ponto espec√≠fico.\n\n### üí° Dica do Pedro:\nPensa na derivada como o \"zoom infinito\" na inclina√ß√£o. Quanto mais voc√™ aumenta o zoom em um pontinho da curva, mais ela parece uma reta. A derivada √© a inclina√ß√£o dessa \"reta imagin√°ria\"!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos visualizar o problema: reta vs curva\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Reta - inclina√ß√£o constante\n",
        "x_reta = np.linspace(0, 5, 100)\n",
        "y_reta = 2*x_reta + 1\n",
        "\n",
        "ax1.plot(x_reta, y_reta, 'b-', linewidth=3, label='y = 2x + 1')\n",
        "ax1.plot([1, 3], [3, 7], 'ro', markersize=8)\n",
        "ax1.plot([1, 3, 3, 1, 1], [3, 3, 7, 7, 3], 'r--', alpha=0.7)\n",
        "ax1.text(2, 2.5, 'Œîx = 2', fontsize=12, ha='center')\n",
        "ax1.text(3.2, 5, 'Œîy = 4', fontsize=12, ha='center')\n",
        "ax1.text(2, 8, 'Inclina√ß√£o = 4/2 = 2\\n(sempre a mesma!)', \n",
        "         fontsize=12, ha='center', bbox=dict(boxstyle=\"round\", facecolor='lightblue'))\n",
        "ax1.set_title('RETA: Inclina√ß√£o Constante', fontsize=14, fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.legend()\n",
        "\n",
        "# Curva - inclina√ß√£o vari√°vel\n",
        "x_curva = np.linspace(0, 4, 100)\n",
        "y_curva = x_curva**2\n",
        "\n",
        "ax2.plot(x_curva, y_curva, 'g-', linewidth=3, label='y = x¬≤')\n",
        "\n",
        "# V√°rios pontos mostrando inclina√ß√µes diferentes\n",
        "pontos_x = [0.5, 1.5, 2.5, 3.5]\n",
        "for i, px in enumerate(pontos_x):\n",
        "    py = px**2\n",
        "    # Desenhar pequenas retas tangentes\n",
        "    inclinacao = 2*px  # derivada de x¬≤\n",
        "    x_tang = np.linspace(px-0.3, px+0.3, 10)\n",
        "    y_tang = py + inclinacao*(x_tang - px)\n",
        "    ax2.plot(x_tang, y_tang, 'r-', linewidth=2, alpha=0.8)\n",
        "    ax2.plot(px, py, 'ro', markersize=6)\n",
        "    ax2.text(px, py+1, f'inclina√ß√£o\\n‚âà {inclinacao:.1f}', \n",
        "             fontsize=10, ha='center', \n",
        "             bbox=dict(boxstyle=\"round\", facecolor='lightyellow', alpha=0.8))\n",
        "\n",
        "ax2.set_title('CURVA: Inclina√ß√£o Muda!', fontsize=14, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üéØ Sacou a diferen√ßa? Na reta, a inclina√ß√£o √© sempre 2.\")\n",
        "print(\"üåä Na curva, cada ponto tem uma inclina√ß√£o diferente!\")\n",
        "print(\"‚ú® A derivada nos d√° a inclina√ß√£o EXATA em cada ponto!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üßÆ A Defini√ß√£o Formal da Derivada\n\nT√°, agora vem a parte mais importante! Lembra dos **limites** que a gente viu no m√≥dulo 3? Eles voltaram pra nos ajudar!\n\nA derivada de uma fun√ß√£o $f(x)$ no ponto $x$ √© definida como:\n\n$$f'(x) = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h}$$\n\n### Traduzindo pro portugu√™s:\n- Pegamos um ponto $x$ na fun√ß√£o\n- Pegamos outro ponto bem pertinho: $x+h$ (onde $h$ √© um n√∫mero pequeninho)\n- Calculamos a inclina√ß√£o entre esses dois pontos: $\\frac{f(x+h) - f(x)}{h}$\n- Fazemos $h$ ficar cada vez menor (tender a zero)\n- O resultado √© a inclina√ß√£o **exata** no ponto $x$!\n\n### üáßüá∑ Analogia Brasileira:\n√â como medir a inclina√ß√£o de uma ladeira no Rio de Janeiro. Se voc√™ medir a inclina√ß√£o m√©dia de Santa Teresa at√© Copacabana, vai dar uma coisa. Mas se voc√™ quer saber a inclina√ß√£o **exata** bem na frente da sua casa, voc√™ precisa medir um pedacinho bem pequeninho da rua!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/c√°lculo-para-ia-modulo-04_img_02.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos implementar a defini√ß√£o de derivada na pr√°tica!\n",
        "def derivada_numerica(f, x, h=1e-7):\n",
        "    \"\"\"\n",
        "    Calcula a derivada num√©rica usando a defini√ß√£o\n",
        "    f'(x) ‚âà [f(x+h) - f(x)] / h\n",
        "    \"\"\"\n",
        "    return (f(x + h) - f(x)) / h\n",
        "\n",
        "# Vamos testar com f(x) = x¬≤\n",
        "def f(x):\n",
        "    return x**2\n",
        "\n",
        "# Testando em alguns pontos\n",
        "pontos_teste = [0, 1, 2, 3, 4]\n",
        "\n",
        "print(\"üßÆ Testando a derivada num√©rica de f(x) = x¬≤:\")\n",
        "print(\"=\"*50)\n",
        "print(f\"{'x':<5} {'f(x)':<8} {'f\\'(x) num√©rica':<15} {'f\\'(x) exata':<12} {'Diferen√ßa':<10}\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "for x in pontos_teste:\n",
        "    fx = f(x)\n",
        "    derivada_num = derivada_numerica(f, x)\n",
        "    derivada_exata = 2*x  # sabemos que a derivada de x¬≤ √© 2x\n",
        "    diferenca = abs(derivada_num - derivada_exata)\n",
        "    \n",
        "    print(f\"{x:<5} {fx:<8} {derivada_num:<15.6f} {derivada_exata:<12} {diferenca:<10.2e}\")\n",
        "\n",
        "print(\"\\nüéâ Liiindo! A aproxima√ß√£o num√©rica t√° quase perfeita!\")\n",
        "print(\"üí° Quanto menor o h, mais precisa fica a aproxima√ß√£o!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìê A Reta Tangente: O Cora√ß√£o da Derivada\n\nAgora chegou a parte mais **liinda** da hist√≥ria! A derivada n√£o √© s√≥ um n√∫mero solto - ela tem um significado geom√©trico super importante:\n\n**A derivada de uma fun√ß√£o em um ponto √© exatamente a inclina√ß√£o da reta tangente naquele ponto!**\n\n### O que √© uma reta tangente?\n√â uma reta que \"encosta\" na curva em um ponto espec√≠fico, tendo a **mesma dire√ß√£o** que a curva naquele momento.\n\n### Equa√ß√£o da reta tangente:\nSe temos uma fun√ß√£o $f(x)$ e queremos a reta tangente no ponto $(a, f(a))$:\n\n$$y - f(a) = f'(a) \\cdot (x - a)$$\n\nOu reorganizando:\n\n$$y = f'(a) \\cdot (x - a) + f(a)$$\n\nonde:\n- $f'(a)$ √© a **inclina√ß√£o** (nossa derivada!)\n- $(a, f(a))$ √© o **ponto de tang√™ncia**\n\n### üí° Dica do Pedro:\nA reta tangente √© como se voc√™ colocasse uma r√©gua bem lisinha encostando na curva. A inclina√ß√£o dessa r√©gua √© exatamente o valor da derivada!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos visualizar retas tangentes interativas!\n",
        "def plotar_tangente(funcao, derivada, ponto_x, titulo=\"Reta Tangente\"):\n",
        "    \"\"\"\n",
        "    Plota uma fun√ß√£o e sua reta tangente em um ponto espec√≠fico\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    \n",
        "    # Dom√≠nio da fun√ß√£o\n",
        "    x = np.linspace(-1, 5, 1000)\n",
        "    y = funcao(x)\n",
        "    \n",
        "    # Plotar a fun√ß√£o original\n",
        "    ax.plot(x, y, 'b-', linewidth=3, label=f'f(x)', alpha=0.8)\n",
        "    \n",
        "    # Ponto de tang√™ncia\n",
        "    ponto_y = funcao(ponto_x)\n",
        "    ax.plot(ponto_x, ponto_y, 'ro', markersize=12, label=f'Ponto ({ponto_x}, {ponto_y:.1f})')\n",
        "    \n",
        "    # Calcular a derivada no ponto\n",
        "    inclinacao = derivada(ponto_x)\n",
        "    \n",
        "    # Reta tangente: y - y0 = m(x - x0)\n",
        "    x_tangente = np.linspace(ponto_x - 2, ponto_x + 2, 100)\n",
        "    y_tangente = inclinacao * (x_tangente - ponto_x) + ponto_y\n",
        "    \n",
        "    ax.plot(x_tangente, y_tangente, 'r--', linewidth=3, \n",
        "            label=f'Reta Tangente (inclina√ß√£o = {inclinacao:.2f})', alpha=0.9)\n",
        "    \n",
        "    # Desenhar o tri√¢ngulo da inclina√ß√£o\n",
        "    if inclinacao != 0:\n",
        "        delta_x = 1\n",
        "        delta_y = inclinacao * delta_x\n",
        "        \n",
        "        # Tri√¢ngulo mostrando rise/run\n",
        "        triangle_x = [ponto_x, ponto_x + delta_x, ponto_x + delta_x, ponto_x]\n",
        "        triangle_y = [ponto_y, ponto_y, ponto_y + delta_y, ponto_y]\n",
        "        ax.plot(triangle_x, triangle_y, 'g-', linewidth=2, alpha=0.7)\n",
        "        ax.fill(triangle_x, triangle_y, 'green', alpha=0.2)\n",
        "        \n",
        "        # Anota√ß√µes\n",
        "        ax.annotate(f'Œîx = {delta_x}', \n",
        "                   xy=(ponto_x + delta_x/2, ponto_y - 0.5), \n",
        "                   fontsize=12, ha='center', color='green', weight='bold')\n",
        "        ax.annotate(f'Œîy = {delta_y:.2f}', \n",
        "                   xy=(ponto_x + delta_x + 0.2, ponto_y + delta_y/2), \n",
        "                   fontsize=12, ha='center', color='green', weight='bold')\n",
        "    \n",
        "    ax.set_title(f'{titulo}\\nDerivada em x={ponto_x}: f\\'({ponto_x}) = {inclinacao:.2f}', \n",
        "                fontsize=16, fontweight='bold')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend(fontsize=12)\n",
        "    ax.set_xlabel('x', fontsize=14)\n",
        "    ax.set_ylabel('f(x)', fontsize=14)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Exemplo 1: f(x) = x¬≤\n",
        "def f1(x):\n",
        "    return x**2\n",
        "\n",
        "def df1(x):\n",
        "    return 2*x\n",
        "\n",
        "print(\"üìä Exemplo 1: f(x) = x¬≤\")\n",
        "plotar_tangente(f1, df1, 2, \"f(x) = x¬≤ no ponto x = 2\")\n",
        "\n",
        "print(\"\\nüéØ Viu como a reta tangente 'encosta' perfeitamente na par√°bola?\")\n",
        "print(\"üìê A inclina√ß√£o da reta tangente = valor da derivada!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos ver v√°rios pontos ao mesmo tempo!\n",
        "fig, ax = plt.subplots(figsize=(14, 10))\n",
        "\n",
        "# Fun√ß√£o f(x) = x¬≤\n",
        "x = np.linspace(-2, 4, 1000)\n",
        "y = x**2\n",
        "ax.plot(x, y, 'b-', linewidth=4, label='f(x) = x¬≤', alpha=0.8)\n",
        "\n",
        "# V√°rios pontos e suas tangentes\n",
        "pontos = [-1, 0, 1, 2, 3]\n",
        "cores = ['red', 'green', 'orange', 'purple', 'brown']\n",
        "\n",
        "for i, px in enumerate(pontos):\n",
        "    py = px**2\n",
        "    inclinacao = 2*px  # derivada de x¬≤\n",
        "    \n",
        "    # Ponto\n",
        "    ax.plot(px, py, 'o', color=cores[i], markersize=10)\n",
        "    \n",
        "    # Reta tangente\n",
        "    x_tang = np.linspace(px - 1.5, px + 1.5, 100)\n",
        "    y_tang = inclinacao * (x_tang - px) + py\n",
        "    ax.plot(x_tang, y_tang, '--', color=cores[i], linewidth=2, alpha=0.8,\n",
        "            label=f'x={px}: f\\'(x)={inclinacao}')\n",
        "    \n",
        "    # Anota√ß√£o\n",
        "    offset_y = 2 if py < 5 else -2\n",
        "    ax.annotate(f'({px}, {py})\\nf\\'({px}) = {inclinacao}', \n",
        "               xy=(px, py), xytext=(px + 0.5, py + offset_y),\n",
        "               fontsize=11, ha='center', weight='bold',\n",
        "               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=cores[i], alpha=0.3),\n",
        "               arrowprops=dict(arrowstyle='->', color=cores[i], lw=1.5))\n",
        "\n",
        "ax.set_title('M√∫ltiplas Retas Tangentes em f(x) = x¬≤', fontsize=16, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax.set_xlabel('x', fontsize=14)\n",
        "ax.set_ylabel('f(x)', fontsize=14)\n",
        "ax.set_xlim(-2.5, 4.5)\n",
        "ax.set_ylim(-2, 16)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üé® Cada cor representa um ponto diferente!\")\n",
        "print(\"üìà Veja como as tangentes ficam mais 'em p√©' conforme x aumenta\")\n",
        "print(\"üîç Em x=0, a tangente √© horizontal (derivada = 0)!\")\n",
        "print(\"‚ö° Em x negativo, a tangente 'desce' (derivada negativa)!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Interpreta√ß√£o F√≠sica: Velocidade Instant√¢nea\n\nBora pra uma aplica√ß√£o super cl√°ssica que vai fazer tudo fazer sentido!\n\nImagina que voc√™ tem a **posi√ß√£o** de um objeto em fun√ß√£o do tempo: $s(t)$\n\n- $s(t)$ = posi√ß√£o no tempo $t$\n- $s'(t)$ = **velocidade instant√¢nea** no tempo $t$\n- $s''(t)$ = acelera√ß√£o no tempo $t$ (derivada da derivada!)\n\n### Por que isso funciona?\n\nA velocidade m√©dia entre dois momentos √©:\n$$v_{\\text{m√©dia}} = \\frac{\\text{dist√¢ncia percorrida}}{\\text{tempo decorrido}} = \\frac{s(t_2) - s(t_1)}{t_2 - t_1}$$\n\nA velocidade **instant√¢nea** √© quando fazemos o intervalo de tempo tender a zero:\n$$v(t) = \\lim_{\\Delta t \\to 0} \\frac{s(t + \\Delta t) - s(t)}{\\Delta t} = s'(t)$$\n\n**Essa √© exatamente a defini√ß√£o de derivada!**\n\n### üèéÔ∏è Analogia do F√≥rmula 1:\nNo aut√≥dromo de Interlagos, quando o piloto passa pela reta dos boxes, o cron√¥metro mostra a velocidade **naquele exato momento**. Isso √© a derivada da posi√ß√£o!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/c√°lculo-para-ia-modulo-04_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simula√ß√£o: Movimento de um objeto\n",
        "# Posi√ß√£o: s(t) = -5t¬≤ + 20t + 10 (movimento com desacelera√ß√£o)\n",
        "\n",
        "def posicao(t):\n",
        "    \"\"\"Posi√ß√£o em fun√ß√£o do tempo\"\"\"\n",
        "    return -5*t**2 + 20*t + 10\n",
        "\n",
        "def velocidade(t):\n",
        "    \"\"\"Velocidade = derivada da posi√ß√£o\"\"\"\n",
        "    return -10*t + 20\n",
        "\n",
        "def aceleracao(t):\n",
        "    \"\"\"Acelera√ß√£o = derivada da velocidade\"\"\"\n",
        "    return -10  # constante!\n",
        "\n",
        "# Tempo de 0 a 5 segundos\n",
        "t = np.linspace(0, 5, 1000)\n",
        "s = posicao(t)\n",
        "v = velocidade(t)\n",
        "a = aceleracao(t)\n",
        "\n",
        "# Criar subplots\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 12))\n",
        "\n",
        "# Gr√°fico da posi√ß√£o\n",
        "ax1.plot(t, s, 'b-', linewidth=3, label='Posi√ß√£o s(t)')\n",
        "ax1.set_title('Posi√ß√£o vs Tempo', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylabel('Posi√ß√£o (m)', fontsize=12)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.legend()\n",
        "\n",
        "# Marcar alguns pontos importantes\n",
        "tempos_importantes = [0, 1, 2, 3, 4]\n",
        "for ti in tempos_importantes:\n",
        "    si = posicao(ti)\n",
        "    vi = velocidade(ti)\n",
        "    ax1.plot(ti, si, 'ro', markersize=8)\n",
        "    ax1.annotate(f't={ti}s\\ns={si:.1f}m\\nv={vi:.1f}m/s', \n",
        "                xy=(ti, si), xytext=(ti + 0.3, si + 5),\n",
        "                fontsize=10, ha='left',\n",
        "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightblue', alpha=0.7),\n",
        "                arrowprops=dict(arrowstyle='->', color='red', lw=1))\n",
        "\n",
        "# Gr√°fico da velocidade\n",
        "ax2.plot(t, v, 'g-', linewidth=3, label='Velocidade v(t) = s\\'(t)')\n",
        "ax2.axhline(y=0, color='r', linestyle='--', alpha=0.5, label='v = 0')\n",
        "ax2.set_title('Velocidade vs Tempo (Derivada da Posi√ß√£o)', fontsize=14, fontweight='bold')\n",
        "ax2.set_ylabel('Velocidade (m/s)', fontsize=12)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.legend()\n",
        "\n",
        "# Marcar quando a velocidade √© zero\n",
        "t_parada = 2  # quando v(t) = 0\n",
        "ax2.plot(t_parada, 0, 'ro', markersize=10)\n",
        "ax2.annotate('Velocidade = 0\\n(Mudan√ßa de dire√ß√£o!)', \n",
        "            xy=(t_parada, 0), xytext=(t_parada + 0.5, 5),\n",
        "            fontsize=12, ha='left', weight='bold',\n",
        "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='yellow', alpha=0.8),\n",
        "            arrowprops=dict(arrowstyle='->', color='red', lw=2))\n",
        "\n",
        "# Gr√°fico da acelera√ß√£o\n",
        "ax3.plot(t, [a]*len(t), 'r-', linewidth=3, label='Acelera√ß√£o a(t) = v\\'(t)')\n",
        "ax3.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
        "ax3.set_title('Acelera√ß√£o vs Tempo (Derivada da Velocidade)', fontsize=14, fontweight='bold')\n",
        "ax3.set_ylabel('Acelera√ß√£o (m/s¬≤)', fontsize=12)\n",
        "ax3.set_xlabel('Tempo (s)', fontsize=12)\n",
        "ax3.grid(True, alpha=0.3)\n",
        "ax3.legend()\n",
        "\n",
        "ax3.text(2.5, -8, 'Acelera√ß√£o constante = -10 m/s¬≤\\n(Desacelera√ß√£o)', \n",
        "         fontsize=12, ha='center', weight='bold',\n",
        "         bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='lightcoral', alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üöó An√°lise do movimento:\")\n",
        "print(\"üìç Posi√ß√£o inicial: 10m\")\n",
        "print(\"üèÉ Velocidade inicial: 20 m/s\")\n",
        "print(\"üõë Em t=2s: velocidade = 0 (objeto para!)\")\n",
        "print(\"üîÑ Depois de t=2s: velocidade fica negativa (volta pra tr√°s!)\")\n",
        "print(\"‚¨áÔ∏è Acelera√ß√£o sempre -10 m/s¬≤ (freando constantemente)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Conex√£o com IA: A Fun√ß√£o de Custo\n\nAgora vem a parte que conecta com nosso curso de **C√°lculo para IA**! Lembra da nossa \"montanha do erro\" l√° do M√≥dulo 1?\n\nA **fun√ß√£o de custo** $J(\\theta)$ mede o qu√£o \"errado\" nosso modelo est√°. Queremos encontrar o ponto onde o erro √© **m√≠nimo**.\n\n### Como a derivada nos ajuda?\n- Se $J'(\\theta) > 0$: a fun√ß√£o t√° \"subindo\" ‚Üí devemos ir pra **esquerda**\n- Se $J'(\\theta) < 0$: a fun√ß√£o t√° \"descendo\" ‚Üí devemos ir pra **direita**  \n- Se $J'(\\theta) = 0$: achamos um **ponto cr√≠tico** (m√≠nimo, m√°ximo ou ponto de sela)\n\n### üéØ O Gradiente Descendente (spoiler do m√≥dulo 11!):\n$$\\theta_{\\text{novo}} = \\theta_{\\text{atual}} - \\alpha \\cdot J'(\\theta_{\\text{atual}})$$\n\nonde:\n- $\\alpha$ = taxa de aprendizado\n- $J'(\\theta)$ = nossa derivada (dire√ß√£o do erro!)\n\n**A derivada √© literalmente a b√∫ssola que guia o aprendizado de m√°quina!**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulando uma fun√ß√£o de custo simples\n",
        "def custo(theta):\n",
        "    \"\"\"Fun√ß√£o de custo quadr√°tica simples\"\"\"\n",
        "    return (theta - 3)**2 + 1\n",
        "\n",
        "def derivada_custo(theta):\n",
        "    \"\"\"Derivada da fun√ß√£o de custo\"\"\"\n",
        "    return 2*(theta - 3)\n",
        "\n",
        "# Dom√≠nio para visualiza√ß√£o\n",
        "theta = np.linspace(-1, 7, 1000)\n",
        "J = custo(theta)\n",
        "dJ = derivada_custo(theta)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
        "\n",
        "# Fun√ß√£o de custo\n",
        "ax1.plot(theta, J, 'b-', linewidth=3, label='J(Œ∏) = Fun√ß√£o de Custo')\n",
        "ax1.set_title('Fun√ß√£o de Custo - Queremos Minimizar!', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylabel('J(Œ∏) - Custo', fontsize=12)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Marcar o m√≠nimo\n",
        "theta_min = 3\n",
        "custo_min = custo(theta_min)\n",
        "ax1.plot(theta_min, custo_min, 'ro', markersize=12, label=f'M√≠nimo Global: Œ∏={theta_min}')\n",
        "ax1.annotate('üéØ OBJETIVO:\\nEncontrar este ponto!', \n",
        "            xy=(theta_min, custo_min), xytext=(theta_min + 1.5, custo_min + 3),\n",
        "            fontsize=12, ha='center', weight='bold',\n",
        "            bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='lightgreen', alpha=0.8),\n",
        "            arrowprops=dict(arrowstyle='->', color='red', lw=2))\n",
        "\n",
        "# Alguns pontos de exemplo\n",
        "pontos_exemplo = [0, 1.5, 4.5, 6]\n",
        "for i, p in enumerate(pontos_exemplo):\n",
        "    custo_p = custo(p)\n",
        "    derivada_p = derivada_custo(p)\n",
        "    ax1.plot(p, custo_p, 'go', markersize=8)\n",
        "    \n",
        "    # Desenhar seta indicando dire√ß√£o\n",
        "    direcao = -1 if derivada_p > 0 else 1\n",
        "    ax1.arrow(p, custo_p + 2, direcao * 0.5, 0, head_width=0.3, \n",
        "             head_length=0.1, fc='orange', ec='orange', linewidth=2)\n",
        "    \n",
        "    sinal = '+' if derivada_p > 0 else '-' if derivada_p < 0 else '0'\n",
        "    ax1.text(p, custo_p + 4, f'Œ∏={p}\\nJ\\'={derivada_p:.1f}\\n({sinal})', \n",
        "            ha='center', fontsize=10, weight='bold',\n",
        "            bbox=dict(boxstyle=\"round,pad=0.2\", facecolor='lightyellow', alpha=0.8))\n",
        "\n",
        "ax1.legend()\n",
        "\n",
        "# Derivada da fun√ß√£o de custo\n",
        "ax2.plot(theta, dJ, 'r-', linewidth=3, label=\"J'(Œ∏) = Derivada do Custo\")\n",
        "ax2.axhline(y=0, color='k', linestyle='--', alpha=0.7, label='Derivada = 0')\n",
        "ax2.axvline(x=theta_min, color='g', linestyle='--', alpha=0.7, label=f'Œ∏ √≥timo = {theta_min}')\n",
        "ax2.set_title('Derivada da Fun√ß√£o de Custo - Nossa B√∫ssola!', fontsize=14, fontweight='bold')\n",
        "ax2.set_ylabel(\"J'(Œ∏)\", fontsize=12)\n",
        "ax2.set_xlabel('Œ∏ (par√¢metro do modelo)', fontsize=12)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Zonas de comportamento\n",
        "ax2.fill_between(theta[theta < theta_min], dJ[theta < theta_min], alpha=0.3, color='red', \n",
        "                label='Derivada > 0: ir √† esquerda')\n",
        "ax2.fill_between(theta[theta > theta_min], dJ[theta > theta_min], alpha=0.3, color='blue',\n",
        "                label='Derivada < 0: ir √† direita')\n",
        "\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üéØ Interpreta√ß√£o pr√°tica:\")\n",
        "print(\"üìà Derivada POSITIVA ‚Üí fun√ß√£o subindo ‚Üí v√° para a ESQUERDA\")\n",
        "print(\"üìâ Derivada NEGATIVA ‚Üí fun√ß√£o descendo ‚Üí v√° para a DIREITA\")\n",
        "print(\"üé™ Derivada ZERO ‚Üí encontrou um ponto cr√≠tico!\")\n",
        "print(\"\\nüöÄ √â assim que o Gradiente Descendente funciona!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Fluxograma: Como Calcular uma Derivada\n\nBora organizar todo o processo num fluxograma bem did√°tico!\n\n```mermaid\ngraph TD\n    A[üéØ Tenho uma fun√ß√£o f(x)] --> B[üìç Escolho um ponto x]\n    B --> C[üìè Defino um h pequeno]\n    C --> D[üßÆ Calculo f(x+h) - f(x)]\n    D --> E[‚ûó Divido por h]\n    E --> F[üîÑ Fa√ßo h tender a 0]\n    F --> G[‚ú® Tenho f'(x)!]\n    G --> H[üìê f'(x) = inclina√ß√£o da reta tangente]\n    H --> I[üé™ Interpreto o resultado]\n    I --> J{Qual aplica√ß√£o?}\n    J -->|F√≠sica| K[üèéÔ∏è Velocidade instant√¢nea]\n    J -->|IA| L[ü§ñ Dire√ß√£o do gradiente]\n    J -->|Economia| M[üí∞ Taxa marginal]\n    J -->|Geometria| N[üìê Inclina√ß√£o da curva]\n```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implementa√ß√£o completa: calculadora de derivadas!\n",
        "class CalculadoraDerivadas:\n",
        "    def __init__(self, funcao, nome_funcao=\"f(x)\"):\n",
        "        self.f = funcao\n",
        "        self.nome = nome_funcao\n",
        "    \n",
        "    def derivada_numerica(self, x, h=1e-8):\n",
        "        \"\"\"Calcula derivada usando defini√ß√£o num√©rica\"\"\"\n",
        "        return (self.f(x + h) - self.f(x)) / h\n",
        "    \n",
        "    def reta_tangente(self, x_ponto):\n",
        "        \"\"\"Retorna fun√ß√£o da reta tangente no ponto dado\"\"\"\n",
        "        y_ponto = self.f(x_ponto)\n",
        "        inclinacao = self.derivada_numerica(x_ponto)\n",
        "        \n",
        "        def tangente(x):\n",
        "            return inclinacao * (x - x_ponto) + y_ponto\n",
        "        \n",
        "        return tangente, inclinacao\n",
        "    \n",
        "    def analisar_ponto(self, x):\n",
        "        \"\"\"An√°lise completa de um ponto\"\"\"\n",
        "        fx = self.f(x)\n",
        "        derivada = self.derivada_numerica(x)\n",
        "        \n",
        "        print(f\"üìä An√°lise do ponto x = {x}:\")\n",
        "        print(f\"   üéØ {self.nome}({x}) = {fx:.4f}\")\n",
        "        print(f\"   üìê f'({x}) = {derivada:.4f}\")\n",
        "        \n",
        "        if abs(derivada) < 1e-6:\n",
        "            print(f\"   üé™ PONTO CR√çTICO: derivada ‚âà 0!\")\n",
        "        elif derivada > 0:\n",
        "            print(f\"   üìà Fun√ß√£o CRESCENTE (subindo)\")\n",
        "        else:\n",
        "            print(f\"   üìâ Fun√ß√£o DECRESCENTE (descendo)\")\n",
        "        \n",
        "        # Interpreta√ß√£o da inclina√ß√£o\n",
        "        if abs(derivada) < 0.1:\n",
        "            print(f\"   üèîÔ∏è Inclina√ß√£o SUAVE\")\n",
        "        elif abs(derivada) < 1:\n",
        "            print(f\"   ‚õ∞Ô∏è Inclina√ß√£o MODERADA\")\n",
        "        else:\n",
        "            print(f\"   üóª Inclina√ß√£o √çNGREME\")\n",
        "        \n",
        "        return fx, derivada\n",
        "\n",
        "# Testando com diferentes fun√ß√µes\n",
        "print(\"üß™ TESTE 1: f(x) = x¬≤\")\n",
        "calc1 = CalculadoraDerivadas(lambda x: x**2, \"f(x) = x¬≤\")\n",
        "calc1.analisar_ponto(0)\n",
        "calc1.analisar_ponto(2)\n",
        "calc1.analisar_ponto(-1)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üß™ TESTE 2: f(x) = sin(x)\")\n",
        "calc2 = CalculadoraDerivadas(lambda x: np.sin(x), \"f(x) = sin(x)\")\n",
        "calc2.analisar_ponto(0)\n",
        "calc2.analisar_ponto(np.pi/2)\n",
        "calc2.analisar_ponto(np.pi)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üß™ TESTE 3: f(x) = e^x\")\n",
        "calc3 = CalculadoraDerivadas(lambda x: np.exp(x), \"f(x) = e^x\")\n",
        "calc3.analisar_ponto(0)\n",
        "calc3.analisar_ponto(1)\n",
        "calc3.analisar_ponto(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéÆ EXERC√çCIO 1: Detetive das Derivadas\n\nAgora √© sua vez de ser o **detetive das derivadas**! üïµÔ∏è‚Äç‚ôÇÔ∏è\n\n### Sua miss√£o:\n1. Complete as fun√ß√µes abaixo\n2. Encontre onde a derivada √© zero\n3. Interprete o resultado fisicamente\n\n### üí° Dica do Pedro:\nQuando a derivada √© zero, algo interessante acontece! Pode ser um m√°ximo, m√≠nimo, ou ponto de inflex√£o!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERC√çCIO 1: Complete o c√≥digo!\n",
        "\n",
        "def exercicio_derivadas():\n",
        "    print(\"üéÆ EXERC√çCIO: An√°lise de uma par√°bola\")\n",
        "    print(\"Fun√ß√£o: f(x) = -2x¬≤ + 8x + 3\")\n",
        "    print(\"\\nüéØ Sua miss√£o:\")\n",
        "    print(\"1. Implementar a fun√ß√£o\")\n",
        "    print(\"2. Implementar sua derivada\")\n",
        "    print(\"3. Encontrar onde f'(x) = 0\")\n",
        "    print(\"4. Interpretar o resultado\\n\")\n",
        "    \n",
        "    # TODO: Complete estas fun√ß√µes!\n",
        "    def f(x):\n",
        "        # TODO: Implementar f(x) = -2x¬≤ + 8x + 3\n",
        "        return  # Sua resposta aqui\n",
        "    \n",
        "    def df_dx(x):\n",
        "        # TODO: Implementar a derivada f'(x) = -4x + 8\n",
        "        return  # Sua resposta aqui\n",
        "    \n",
        "    # TODO: Encontrar onde a derivada √© zero\n",
        "    # Resolver: -4x + 8 = 0\n",
        "    x_critico = None  # Sua resposta aqui\n",
        "    \n",
        "    if x_critico is not None:\n",
        "        y_critico = f(x_critico)\n",
        "        print(f\"üé™ Ponto cr√≠tico encontrado: x = {x_critico}\")\n",
        "        print(f\"üìç Valor da fun√ß√£o: f({x_critico}) = {y_critico}\")\n",
        "        print(f\"üìê Valor da derivada: f'({x_critico}) = {df_dx(x_critico)}\")\n",
        "        \n",
        "        # Verificar se √© m√°ximo ou m√≠nimo\n",
        "        # TODO: Como voc√™ pode determinar isso?\n",
        "        \n",
        "        # Plotar para visualizar\n",
        "        x = np.linspace(-2, 6, 1000)\n",
        "        y = f(x)\n",
        "        dy = df_dx(x)\n",
        "        \n",
        "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
        "        \n",
        "        ax1.plot(x, y, 'b-', linewidth=3, label='f(x) = -2x¬≤ + 8x + 3')\n",
        "        ax1.plot(x_critico, y_critico, 'ro', markersize=12, label=f'Ponto cr√≠tico')\n",
        "        ax1.set_title('Fun√ß√£o Original')\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.legend()\n",
        "        \n",
        "        ax2.plot(x, dy, 'r-', linewidth=3, label=\"f'(x) = -4x + 8\")\n",
        "        ax2.axhline(y=0, color='k', linestyle='--', alpha=0.7)\n",
        "        ax2.plot(x_critico, 0, 'ro', markersize=12, label='Derivada = 0')\n",
        "        ax2.set_title('Derivada')\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        ax2.legend()\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    print(\"\\nü§î Quest√µes para reflex√£o:\")\n",
        "    print(\"‚Ä¢ Este ponto cr√≠tico √© um m√°ximo ou m√≠nimo?\")\n",
        "    print(\"‚Ä¢ Como voc√™ pode ter certeza?\")\n",
        "    print(\"‚Ä¢ O que acontece com a fun√ß√£o antes e depois deste ponto?\")\n",
        "\n",
        "# Descomente a linha abaixo quando terminar!\n",
        "# exercicio_derivadas()\n",
        "\n",
        "print(\"‚ö†Ô∏è Complete o c√≥digo acima e descomente a √∫ltima linha para ver o resultado!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ EXERC√çCIO 2: Aplica√ß√£o na IA - Otimiza√ß√£o\n\nAgora vamos aplicar derivadas num problema real de **otimiza√ß√£o em IA**!\n\n### Cen√°rio:\nVoc√™ tem um modelo simples com um par√¢metro $w$ e quer minimizar o erro quadr√°tico m√©dio:\n\n$$J(w) = \\frac{1}{2}(w - 5)^2 + 2$$\n\n### Sua miss√£o:\n1. Implementar a fun√ß√£o de custo\n2. Implementar sua derivada  \n3. Simular 5 passos do gradiente descendente\n4. Visualizar a otimiza√ß√£o\n\n### üí° Dica do Pedro:\nO gradiente descendente usa a f√≥rmula: $w_{novo} = w_{atual} - \\alpha \\cdot J'(w_{atual})$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERC√çCIO 2: Gradiente Descendente Simples\n",
        "\n",
        "def exercicio_gradiente():\n",
        "    print(\"ü§ñ EXERC√çCIO: Otimiza√ß√£o com Gradiente Descendente\")\n",
        "    print(\"Fun√ß√£o de Custo: J(w) = 0.5(w - 5)¬≤ + 2\")\n",
        "    print(\"Objetivo: Encontrar o w que minimiza J(w)\\n\")\n",
        "    \n",
        "    # TODO: Complete estas fun√ß√µes!\n",
        "    def custo(w):\n",
        "        # TODO: Implementar J(w) = 0.5(w - 5)¬≤ + 2\n",
        "        return  # Sua resposta aqui\n",
        "    \n",
        "    def derivada_custo(w):\n",
        "        # TODO: Implementar J'(w) = (w - 5)\n",
        "        return  # Sua resposta aqui\n",
        "    \n",
        "    # Par√¢metros do gradiente descendente\n",
        "    w_inicial = 0.0  # Chute inicial\n",
        "    taxa_aprendizado = 0.3  # Œ± (alpha)\n",
        "    num_iteracoes = 5\n",
        "    \n",
        "    # Listas para armazenar hist√≥rico\n",
        "    historico_w = [w_inicial]\n",
        "    historico_custo = [custo(w_inicial)]\n",
        "    \n",
        "    print(f\"üöÄ Come√ßando otimiza√ß√£o:\")\n",
        "    print(f\"   w inicial = {w_inicial}\")\n",
        "    print(f\"   Taxa de aprendizado = {taxa_aprendizado}\")\n",
        "    print(f\"   Itera√ß√µes = {num_iteracoes}\\n\")\n",
        "    \n",
        "    w_atual = w_inicial\n",
        "    \n",
        "    for i in range(num_iteracoes):\n",
        "        # TODO: Complete o algoritmo do gradiente descendente\n",
        "        \n",
        "        # 1. Calcular custo atual\n",
        "        custo_atual =   # Sua resposta aqui\n",
        "        \n",
        "        # 2. Calcular derivada atual  \n",
        "        derivada_atual =   # Sua resposta aqui\n",
        "        \n",
        "        # 3. Atualizar w usando gradiente descendente\n",
        "        w_novo =   # Sua resposta aqui: w_atual - taxa_aprendizado * derivada_atual\n",
        "        \n",
        "        print(f\"üìä Itera√ß√£o {i+1}:\")\n",
        "        print(f\"   w = {w_atual:.4f}\")\n",
        "        print(f\"   J(w) = {custo_atual:.4f}\")\n",
        "        print(f\"   J'(w) = {derivada_atual:.4f}\")\n",
        "        print(f\"   w_novo = {w_novo:.4f}\\n\")\n",
        "        \n",
        "        # Atualizar para pr√≥xima itera√ß√£o\n",
        "        w_atual = w_novo\n",
        "        historico_w.append(w_atual)\n",
        "        historico_custo.append(custo(w_atual))\n",
        "    \n",
        "    # Visualiza√ß√£o\n",
        "    if len(historico_w) > 1:  # Se o exerc√≠cio foi completado\n",
        "        w_range = np.linspace(-2, 8, 1000)\n",
        "        J_range = [custo(w) for w in w_range]\n",
        "        \n",
        "        plt.figure(figsize=(12, 8))\n",
        "        \n",
        "        # Plotar fun√ß√£o de custo\n",
        "        plt.plot(w_range, J_range, 'b-', linewidth=3, label='J(w) = 0.5(w-5)¬≤ + 2')\n",
        "        \n",
        "        # Plotar caminho da otimiza√ß√£o\n",
        "        for i in range(len(historico_w)-1):\n",
        "            plt.plot([historico_w[i], historico_w[i+1]], \n",
        "                    [historico_custo[i], historico_custo[i+1]], \n",
        "                    'ro-', markersize=8, linewidth=2, alpha=0.8)\n",
        "            plt.annotate(f'Passo {i+1}', \n",
        "                        xy=(historico_w[i+1], historico_custo[i+1]),\n",
        "                        xytext=(10, 10), textcoords='offset points',\n",
        "                        fontsize=10, weight='bold')\n",
        "        \n",
        "        # Marcar ponto inicial e final\n",
        "        plt.plot(historico_w[0], historico_custo[0], 'go', markersize=12, \n",
        "                label=f'In√≠cio: w={historico_w[0]:.2f}')\n",
        "        plt.plot(historico_w[-1], historico_custo[-1], 'ro', markersize=12, \n",
        "                label=f'Final: w={historico_w[-1]:.2f}')\n",
        "        \n",
        "        # Marcar m√≠nimo te√≥rico\n",
        "        plt.plot(5, 2, 'k*', markersize=15, label='M√≠nimo te√≥rico: w=5')\n",
        "        \n",
        "        plt.title('Gradiente Descendente em A√ß√£o!', fontsize=16, fontweight='bold')\n",
        "        plt.xlabel('w (par√¢metro)', fontsize=14)\n",
        "        plt.ylabel('J(w) (custo)', fontsize=14)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        \n",
        "        print(f\"üéØ Resultado final:\")\n",
        "        print(f\"   w otimizado ‚âà {historico_w[-1]:.4f}\")\n",
        "        print(f\"   Custo final ‚âà {historico_custo[-1]:.4f}\")\n",
        "        print(f\"   Erro em rela√ß√£o ao √≥timo: {abs(historico_w[-1] - 5):.4f}\")\n",
        "\n",
        "# Descomente quando terminar!\n",
        "# exercicio_gradiente()\n",
        "\n",
        "print(\"‚ö†Ô∏è Complete o c√≥digo acima e descomente a √∫ltima linha!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé™ Casos Especiais e Pegadinhas\n\nNem tudo s√£o flores no mundo das derivadas! Existem alguns casos especiais que voc√™ precisa conhecer:\n\n### 1. üö´ Pontos onde a derivada N√ÉO existe:\n- **Pontos angulosos**: Como no $|x|$ em $x=0$\n- **Descontinuidades**: Onde a fun√ß√£o \"pula\"\n- **Tangentes verticais**: Onde a inclina√ß√£o √© infinita\n\n### 2. ü§î Derivada zero ‚â† M√≠nimo sempre:\n- Pode ser **m√°ximo local**\n- Pode ser **ponto de sela** (nem m√°ximo nem m√≠nimo)\n- Pode ser **ponto de inflex√£o**\n\n### 3. üé≠ Interpreta√ß√µes f√≠sicas:\n- **Posi√ß√£o** ‚Üí derivada = **velocidade**\n- **Velocidade** ‚Üí derivada = **acelera√ß√£o**  \n- **Custo** ‚Üí derivada = **taxa marginal**\n- **Popula√ß√£o** ‚Üí derivada = **taxa de crescimento**\n\n### üí° Dica do Pedro:\nA derivada √© como um \"detector de tend√™ncias\". Ela te diz n√£o s√≥ o valor atual, mas **para onde a coisa t√° indo**!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando casos especiais\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Caso 1: Fun√ß√£o com ponto anguloso |x|\n",
        "x1 = np.linspace(-3, 3, 1000)\n",
        "y1 = np.abs(x1)\n",
        "ax1.plot(x1, y1, 'b-', linewidth=3, label='f(x) = |x|')\n",
        "ax1.plot(0, 0, 'ro', markersize=12, label='Derivada n√£o existe em x=0')\n",
        "ax1.set_title('Ponto Anguloso: f(x) = |x|', fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.legend()\n",
        "ax1.text(0, 2, '‚ö†Ô∏è N√£o √© \"lisa\"\\nnem diferenci√°vel\\nem x = 0', \n",
        "         ha='center', fontsize=11, weight='bold',\n",
        "         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='yellow', alpha=0.8))\n",
        "\n",
        "# Caso 2: Fun√ß√£o com m√°ximo, m√≠nimo e ponto de sela\n",
        "x2 = np.linspace(-2, 2, 1000)\n",
        "y2 = x2**3 - 3*x2  # tem m√°ximo local, m√≠nimo local\n",
        "ax2.plot(x2, y2, 'g-', linewidth=3, label='f(x) = x¬≥ - 3x')\n",
        "\n",
        "# Pontos cr√≠ticos: f'(x) = 3x¬≤ - 3 = 0 ‚Üí x = ¬±1\n",
        "pontos_criticos = [-1, 1]\n",
        "for pc in pontos_criticos:\n",
        "    yc = pc**3 - 3*pc\n",
        "    ax2.plot(pc, yc, 'ro', markersize=10)\n",
        "    tipo = 'M√°ximo local' if pc == -1 else 'M√≠nimo local'\n",
        "    ax2.annotate(f'{tipo}\\nx={pc}, f\\'(x)=0', \n",
        "                xy=(pc, yc), xytext=(pc + 0.5, yc + 1),\n",
        "                fontsize=10, weight='bold',\n",
        "                bbox=dict(boxstyle=\"round,pad=0.2\", facecolor='lightblue', alpha=0.8),\n",
        "                arrowprops=dict(arrowstyle='->', color='red'))\n",
        "\n",
        "ax2.set_title('M√°ximos e M√≠nimos Locais', fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.legend()\n",
        "\n",
        "# Caso 3: Tangente vertical\n",
        "x3 = np.linspace(0.01, 4, 1000)  # evitar x=0\n",
        "y3 = x3**(1/3)  # raiz c√∫bica\n",
        "ax3.plot(x3, y3, 'purple', linewidth=3, label='f(x) = x^(1/3)')\n",
        "ax3.plot(0, 0, 'ro', markersize=12, label='Tangente vertical em x=0')\n",
        "ax3.set_title('Tangente Vertical', fontweight='bold')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "ax3.legend()\n",
        "ax3.text(2, 0.5, 'üìè Em x=0:\\nInclina√ß√£o = ‚àû\\n(tangente vertical)', \n",
        "         ha='center', fontsize=11, weight='bold',\n",
        "         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightcoral', alpha=0.8))\n",
        "\n",
        "# Caso 4: Fun√ß√£o com descontinuidade\n",
        "x4a = np.linspace(-3, 0, 500)\n",
        "x4b = np.linspace(0.01, 3, 500)\n",
        "y4a = x4a + 1\n",
        "y4b = x4b - 1\n",
        "\n",
        "ax4.plot(x4a, y4a, 'orange', linewidth=3, label='f(x) para x < 0')\n",
        "ax4.plot(x4b, y4b, 'orange', linewidth=3, label='f(x) para x > 0')\n",
        "ax4.plot(0, 1, 'ro', markersize=8, label='Limite √† esquerda')\n",
        "ax4.plot(0, -1, 'bo', markersize=8, label='Limite √† direita')\n",
        "ax4.axvline(x=0, color='red', linestyle='--', alpha=0.7)\n",
        "ax4.set_title('Descontinuidade em x=0', fontweight='bold')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "ax4.legend()\n",
        "ax4.text(1.5, 0, 'üí• Fun√ß√£o \"pula\"\\nem x = 0\\nDerivada n√£o existe', \n",
        "         ha='center', fontsize=11, weight='bold',\n",
        "         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightyellow', alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üé≠ Casos especiais resumidos:\")\n",
        "print(\"üìê Ponto anguloso: derivada n√£o existe (n√£o √© 'lisa')\")\n",
        "print(\"üé™ f'(x) = 0: pode ser m√°ximo, m√≠nimo ou ponto de sela\")\n",
        "print(\"üìè Tangente vertical: derivada = ‚àû (n√£o existe)\")\n",
        "print(\"üí• Descontinuidade: fun√ß√£o 'pula', derivada n√£o existe\")\n",
        "print(\"\\nüí° Moral da hist√≥ria: nem sempre d√° pra derivar tudo!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîó Preparando para os Pr√≥ximos M√≥dulos\n\nAgora que voc√™ domina o conceito b√°sico de derivada, vamos ver o que vem pela frente:\n\n### üìö M√≥dulo 5 - Derivadas 2: As Regras do Jogo\n- **Regra da Soma**: $(f + g)' = f' + g'$\n- **Regra do Produto**: $(f \\cdot g)' = f'g + fg'$\n- **Regra do Quociente**: $\\left(\\frac{f}{g}\\right)' = \\frac{f'g - fg'}{g^2}$\n\n### ‚≠ê M√≥dulo 6 - Regra da Cadeia: A Estrela do Show\n- Como derivar fun√ß√µes compostas\n- **A base do backpropagation** em redes neurais!\n- $(f(g(x)))' = f'(g(x)) \\cdot g'(x)$\n\n### üéöÔ∏è M√≥dulos 10-12: Aplica√ß√£o Total em IA\n- Derivadas parciais (m√∫ltiplas vari√°veis)\n- Gradientes (vetor de derivadas)\n- Gradiente Descendente completo\n\n```mermaid\ngraph LR\n    A[üìê Derivada B√°sica<br/>M√≥dulo 4] --> B[üìè Regras de Deriva√ß√£o<br/>M√≥dulo 5]\n    B --> C[‚≠ê Regra da Cadeia<br/>M√≥dulo 6]\n    C --> D[üßÆ M√∫ltiplas Vari√°veis<br/>M√≥dulo 9]\n    D --> E[‚àá Gradientes<br/>M√≥dulo 10]\n    E --> F[ü§ñ Gradiente Descendente<br/>M√≥dulos 11-12]\n    F --> G[üöÄ IA Completa!]\n```\n\n### üí° Dica do Pedro:\nA derivada que voc√™ aprendeu hoje √© literalmente a **funda√ß√£o** de todo aprendizado de m√°quina moderno. Cada vez que uma rede neural \"aprende\", ela t√° usando derivadas para ajustar os pesos!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/c√°lculo-para-ia-modulo-04_img_05.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preview: Como as derivadas conectam com IA\n",
        "print(\"üîÆ PREVIEW: Conex√µes com IA que veremos nos pr√≥ximos m√≥dulos\\n\")\n",
        "\n",
        "# Simula√ß√£o simples de como uma rede neural usa derivadas\n",
        "def demonstracao_backprop_simples():\n",
        "    \"\"\"Demonstra√ß√£o conceitual de como derivadas s√£o usadas em IA\"\"\"\n",
        "    \n",
        "    print(\"üß† Rede Neural Simples: y = œÉ(w*x + b)\")\n",
        "    print(\"onde œÉ √© a fun√ß√£o sigmoid\\n\")\n",
        "    \n",
        "    # Fun√ß√£o sigmoid e sua derivada\n",
        "    def sigmoid(z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "    def sigmoid_derivada(z):\n",
        "        s = sigmoid(z)\n",
        "        return s * (1 - s)\n",
        "    \n",
        "    # Exemplo com dados\n",
        "    x = 2.0  # entrada\n",
        "    w = 0.5  # peso (par√¢metro que queremos otimizar)\n",
        "    b = 0.1  # bias\n",
        "    y_real = 0.8  # valor esperado\n",
        "    \n",
        "    # Forward pass\n",
        "    z = w * x + b\n",
        "    y_pred = sigmoid(z)\n",
        "    erro = (y_pred - y_real)**2  # erro quadr√°tico\n",
        "    \n",
        "    print(f\"üìä Forward Pass:\")\n",
        "    print(f\"   z = w*x + b = {w}*{x} + {b} = {z}\")\n",
        "    print(f\"   y_pred = œÉ({z}) = {y_pred:.4f}\")\n",
        "    print(f\"   y_real = {y_real}\")\n",
        "    print(f\"   Erro = (y_pred - y_real)¬≤ = {erro:.4f}\\n\")\n",
        "    \n",
        "    # Backward pass (usando regra da cadeia!)\n",
        "    print(f\"üîÑ Backward Pass (usando derivadas):\")\n",
        "    \n",
        "    # dErro/dy_pred\n",
        "    dErro_dy = 2 * (y_pred - y_real)\n",
        "    print(f\"   dErro/dy_pred = 2*(y_pred - y_real) = {dErro_dy:.4f}\")\n",
        "    \n",
        "    # dy_pred/dz (derivada do sigmoid)\n",
        "    dy_dz = sigmoid_derivada(z)\n",
        "    print(f\"   dy_pred/dz = œÉ'({z}) = {dy_dz:.4f}\")\n",
        "    \n",
        "    # dz/dw\n",
        "    dz_dw = x\n",
        "    print(f\"   dz/dw = x = {dz_dw}\")\n",
        "    \n",
        "    # Regra da cadeia: dErro/dw = (dErro/dy) * (dy/dz) * (dz/dw)\n",
        "    dErro_dw = dErro_dy * dy_dz * dz_dw\n",
        "    print(f\"   dErro/dw = {dErro_dy:.4f} * {dy_dz:.4f} * {dz_dw} = {dErro_dw:.4f}\\n\")\n",
        "    \n",
        "    # Atualiza√ß√£o do peso\n",
        "    taxa_aprendizado = 0.1\n",
        "    w_novo = w - taxa_aprendizado * dErro_dw\n",
        "    \n",
        "    print(f\"üéØ Atualiza√ß√£o do peso:\")\n",
        "    print(f\"   w_novo = w - Œ± * dErro/dw\")\n",
        "    print(f\"   w_novo = {w} - {taxa_aprendizado} * {dErro_dw:.4f}\")\n",
        "    print(f\"   w_novo = {w_novo:.4f}\\n\")\n",
        "    \n",
        "    print(f\"‚ú® √â assim que a IA aprende: usando DERIVADAS!\")\n",
        "    print(f\"üîó Nos pr√≥ximos m√≥dulos, veremos isso em detalhes!\")\n",
        "\n",
        "demonstracao_backprop_simples()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéì Parab√©ns! Voc√™ completou o M√≥dulo 4!\")\n",
        "print(\"üìê Agora voc√™ sabe o que √© uma derivada e como us√°-la!\")\n",
        "print(\"üöÄ No pr√≥ximo m√≥dulo: as regras para derivar qualquer fun√ß√£o!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéì Resumo do M√≥dulo 4\n\n**Liiindo!** Chegamos ao final de mais um m√≥dulo! Vamos recapitular o que aprendemos:\n\n### üéØ Conceitos Principais:\n1. **Derivada = Taxa de Varia√ß√£o Instant√¢nea**\n   - Como o \"veloc√≠metro\" da matem√°tica\n   - Mede o qu√£o r√°pido uma fun√ß√£o muda\n\n2. **Defini√ß√£o Formal**:\n   $$f'(x) = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h}$$\n\n3. **Interpreta√ß√£o Geom√©trica**:\n   - Derivada = inclina√ß√£o da reta tangente\n   - Reta tangente \"encosta\" na curva\n\n4. **Aplica√ß√µes F√≠sicas**:\n   - Posi√ß√£o ‚Üí Velocidade ‚Üí Acelera√ß√£o\n   - Todas conectadas por derivadas!\n\n5. **Conex√£o com IA**:\n   - Derivadas guiam a otimiza√ß√£o\n   - Base do gradiente descendente\n   - Cora√ß√£o do backpropagation\n\n### üí° Dicas do Pedro para levar pra vida:\n- **Derivada positiva**: fun√ß√£o subindo üìà\n- **Derivada negativa**: fun√ß√£o descendo üìâ  \n- **Derivada zero**: ponto cr√≠tico üé™\n- **Derivada grande**: mudan√ßa r√°pida ‚ö°\n- **Derivada pequena**: mudan√ßa suave üåä\n\n### üîÆ Pr√≥ximo M√≥dulo:\n**Derivadas 2: As Regras do Jogo** - Como derivar fun√ß√µes complexas usando regras simples!\n\n---\n\n**Bora continuar essa jornada rumo ao dom√≠nio da IA! üöÄ**\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/c√°lculo-para-ia-modulo-04_img_06.png)"
      ]
    }
  ]
}