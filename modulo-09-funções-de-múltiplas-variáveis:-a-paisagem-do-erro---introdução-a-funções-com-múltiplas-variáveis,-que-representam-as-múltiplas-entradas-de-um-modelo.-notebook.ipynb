{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ”ï¸ FunÃ§Ãµes de MÃºltiplas VariÃ¡veis: A Paisagem do Erro\n\n## Bem-vindos ao MÃ³dulo 9 do CÃ¡lculo para IA!\n\nE aÃ­, pessoal! Pedro Guth aqui de novo! ğŸš€\n\nTÃ¡, mas atÃ© agora a gente ficou brincando com funÃ§Ãµes de uma variÃ¡vel sÃ³, nÃ©? Tipo aquele exemplo clÃ¡ssico do $f(x) = x^2$. Mas cara, na vida real da IA, as coisas sÃ£o **BEM** mais complicadas!\n\nImagina um modelo de machine learning que precisa prever o preÃ§o de um apartamento no Rio. Ele nÃ£o vai olhar sÃ³ pro tamanho, nÃ©? Vai olhar pro nÃºmero de quartos, banheiros, andar, se tem vista pro mar, se tÃ¡ perto do metrÃ´... SÃ£o **MÃšLTIPLAS** variÃ¡veis!\n\nE Ã© exatamente isso que vamos aprender hoje: **FunÃ§Ãµes de MÃºltiplas VariÃ¡veis** - a paisagem do erro que nossos modelos navegam!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/cÃ¡lculo-para-ia-modulo-09_img_01.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bora comeÃ§ar com os imports! Sempre a mesma coisa, nÃ©?\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import seaborn as sns\n",
        "\n",
        "# Configurando o matplotlib para ficar mais bonito\n",
        "plt.style.use('seaborn-v0_8')\n",
        "plt.rcParams['figure.figsize'] = (10, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"ğŸ¯ Bibliotecas carregadas! Bora mergulhar na paisagem do erro!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¤” Mas afinal, o que sÃ£o FunÃ§Ãµes de MÃºltiplas VariÃ¡veis?\n\nLembra daquele conceito lÃ¡ do **MÃ³dulo 1** sobre a montanha do erro? Pois Ã©, agora a gente vai finalmente entender direito como ela Ã©!\n\n### A Analogia do GPS\n\nPensa assim: quando vocÃª tÃ¡ usando o GPS, ele precisa de **duas** coordenadas para te localizar: latitude e longitude. Uma funÃ§Ã£o de mÃºltiplas variÃ¡veis Ã© exatamente isso!\n\n**FunÃ§Ã£o de uma variÃ¡vel**: $f(x) = x^2$\n- Entrada: um nÃºmero ($x$)\n- SaÃ­da: um nÃºmero ($f(x)$)\n- GrÃ¡fico: uma curva 2D\n\n**FunÃ§Ã£o de duas variÃ¡veis**: $f(x, y) = x^2 + y^2$\n- Entrada: dois nÃºmeros ($x$ e $y$)\n- SaÃ­da: um nÃºmero ($f(x,y)$)\n- GrÃ¡fico: uma superfÃ­cie 3D\n\n**FunÃ§Ã£o de mÃºltiplas variÃ¡veis**: $f(x_1, x_2, ..., x_n) = $ alguma coisa\n- Entrada: $n$ nÃºmeros\n- SaÃ­da: um nÃºmero\n- GrÃ¡fico: impossÃ­vel de visualizar se $n > 2$ ğŸ˜…\n\n### NotaÃ§Ã£o MatemÃ¡tica\n\nA notaÃ§Ã£o formal Ã©:\n\n$$f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$$\n\nQue se lÃª: \"$f$ Ã© uma funÃ§Ã£o que pega $n$ nÃºmeros reais e retorna um nÃºmero real\"\n\n**Dica do Pedro**: NÃ£o se assusta com essa notaÃ§Ã£o! Ã‰ sÃ³ uma forma chique de dizer que a funÃ§Ã£o pega vÃ¡rios nÃºmeros e cospe um nÃºmero sÃ³!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos comeÃ§ar com um exemplo simples: funÃ§Ã£o de duas variÃ¡veis\n",
        "def funcao_2d_simples(x, y):\n",
        "    \"\"\"\n",
        "    FunÃ§Ã£o simples de duas variÃ¡veis: f(x,y) = xÂ² + yÂ²\n",
        "    Essa Ã© a famosa paraboloide!\n",
        "    \"\"\"\n",
        "    return x**2 + y**2\n",
        "\n",
        "# Testando alguns pontos\n",
        "print(\"ğŸ” Testando nossa funÃ§Ã£o f(x,y) = xÂ² + yÂ²:\")\n",
        "print(f\"f(0,0) = {funcao_2d_simples(0, 0)}\")\n",
        "print(f\"f(1,1) = {funcao_2d_simples(1, 1)}\")\n",
        "print(f\"f(2,3) = {funcao_2d_simples(2, 3)}\")\n",
        "print(f\"f(-1,2) = {funcao_2d_simples(-1, 2)}\")\n",
        "\n",
        "# Repara que mesmo com entradas negativas, a saÃ­da Ã© sempre positiva!\n",
        "# Isso porque estamos elevando ao quadrado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Visualizando a Paisagem: GrÃ¡ficos 3D\n\nTÃ¡, mas como que a gente visualiza essas funÃ§Ãµes? Bora criar nossa primeira paisagem 3D!\n\n### O Conceito da SuperfÃ­cie\n\nQuando temos uma funÃ§Ã£o $f(x, y)$, cada ponto $(x, y)$ no plano produz uma altura $z = f(x, y)$. Isso cria uma **superfÃ­cie** no espaÃ§o 3D.\n\nÃ‰ tipo assim:\n- **Eixo X**: primeira variÃ¡vel\n- **Eixo Y**: segunda variÃ¡vel  \n- **Eixo Z**: valor da funÃ§Ã£o (a \"altura\")\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/cÃ¡lculo-para-ia-modulo-09_img_02.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando um grÃ¡fico 3D da nossa funÃ§Ã£o\n",
        "fig = plt.figure(figsize=(12, 9))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Criando uma grade de pontos\n",
        "x = np.linspace(-3, 3, 50)\n",
        "y = np.linspace(-3, 3, 50)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "\n",
        "# Calculando Z = f(X, Y)\n",
        "Z = funcao_2d_simples(X, Y)\n",
        "\n",
        "# Plotando a superfÃ­cie\n",
        "surface = ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.8)\n",
        "\n",
        "# ConfiguraÃ§Ãµes do grÃ¡fico\n",
        "ax.set_xlabel('X (primeira variÃ¡vel)')\n",
        "ax.set_ylabel('Y (segunda variÃ¡vel)')\n",
        "ax.set_zlabel('Z = f(X,Y) (valor da funÃ§Ã£o)')\n",
        "ax.set_title('ğŸ”ï¸ Nossa Primeira Paisagem 3D: f(x,y) = xÂ² + yÂ²')\n",
        "\n",
        "# Adicionando uma barra de cores\n",
        "fig.colorbar(surface, shrink=0.5)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸ’¡ Essa Ã© uma paraboloide! Repara que o ponto mais baixo Ã© em (0,0)\")\n",
        "print(\"   Ã‰ exatamente onde nossa funÃ§Ã£o tem valor mÃ­nimo!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ—ºï¸ Curvas de NÃ­vel: O Mapa TopogrÃ¡fico da FunÃ§Ã£o\n\nCara, Ã s vezes visualizar em 3D Ã© meio complicado, nÃ©? Por isso existe uma tÃ©cnica **MUITO** usada em IA: as **curvas de nÃ­vel** (ou contour plots)!\n\n### A Analogia do Mapa TopogrÃ¡fico\n\nSabe aqueles mapas de montanha que mostram as altitudes com linhas? Ã‰ exatamente isso!\n\n- Cada linha conecta pontos que tÃªm a **mesma altura**\n- Linhas prÃ³ximas = terreno Ã­ngreme\n- Linhas distantes = terreno suave\n- Centro das \"circunferÃªncias\" = picos ou vales\n\nMatematicamente, uma curva de nÃ­vel para o valor $c$ Ã© o conjunto de todos os pontos $(x, y)$ onde:\n\n$$f(x, y) = c$$\n\n**Dica do Pedro**: Curvas de nÃ­vel sÃ£o FUNDAMENTAIS para entender como o gradiente descendente funciona! VocÃª vai ver isso no **MÃ³dulo 11**!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando um mapa de curvas de nÃ­vel\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Curvas de nÃ­vel simples\n",
        "contour = ax1.contour(X, Y, Z, levels=15, colors='black', alpha=0.6)\n",
        "ax1.clabel(contour, inline=True, fontsize=8)\n",
        "ax1.set_xlabel('X')\n",
        "ax1.set_ylabel('Y')\n",
        "ax1.set_title('ğŸ—ºï¸ Curvas de NÃ­vel - Estilo Mapa')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Curvas de nÃ­vel preenchidas (mais bonito!)\n",
        "contourf = ax2.contourf(X, Y, Z, levels=20, cmap='viridis')\n",
        "contour2 = ax2.contour(X, Y, Z, levels=20, colors='white', alpha=0.5, linewidths=0.5)\n",
        "ax2.set_xlabel('X')\n",
        "ax2.set_ylabel('Y')\n",
        "ax2.set_title('ğŸ¨ Curvas de NÃ­vel - Estilo Heat Map')\n",
        "\n",
        "# Adicionando barra de cores\n",
        "plt.colorbar(contourf, ax=ax2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸ¯ Repara como as curvas formam cÃ­rculos concÃªntricos!\")\n",
        "print(\"   Isso significa que nossa funÃ§Ã£o cresce igualmente em todas as direÃ§Ãµes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§  ConexÃ£o com Machine Learning: A FunÃ§Ã£o de Custo\n\nBom, mas por que isso Ã© importante para IA? **SIMPLES**: as funÃ§Ãµes de custo (ou loss functions) que nossos modelos tentam minimizar sÃ£o exatamente isso!\n\n### Exemplo Real: RegressÃ£o Linear Simples\n\nImagina que vocÃª quer fazer uma reta que melhor se ajusta aos seus dados. A reta tem a equaÃ§Ã£o:\n\n$$y = ax + b$$\n\nOnde:\n- $a$ Ã© o coeficiente angular (inclinaÃ§Ã£o)\n- $b$ Ã© o coeficiente linear (onde corta o eixo Y)\n\nA funÃ§Ã£o de custo (Mean Squared Error) seria:\n\n$$J(a, b) = \\frac{1}{2m} \\sum_{i=1}^{m} (ax_i + b - y_i)^2$$\n\nEssa Ã© uma **funÃ§Ã£o de duas variÃ¡veis** ($a$ e $b$) que queremos **minimizar**!\n\n```mermaid\ngraph TD\n    A[Dados de Entrada] --> B[Modelo: y = ax + b]\n    B --> C[PrediÃ§Ãµes]\n    C --> D[FunÃ§Ã£o de Custo J(a,b)]\n    D --> E[Paisagem 3D do Erro]\n    E --> F[Encontrar MÃ­nimo Global]\n```\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/cÃ¡lculo-para-ia-modulo-09_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulando um exemplo real de regressÃ£o linear\n",
        "np.random.seed(42)  # Para reproduzibilidade\n",
        "\n",
        "# Gerando dados sintÃ©ticos\n",
        "n_samples = 20\n",
        "x_data = np.linspace(0, 10, n_samples)\n",
        "y_true = 2.5 * x_data + 1.0  # RelaÃ§Ã£o verdadeira: y = 2.5x + 1\n",
        "y_data = y_true + np.random.normal(0, 1, n_samples)  # Adicionando ruÃ­do\n",
        "\n",
        "def funcao_custo_mse(a, b, x_data, y_data):\n",
        "    \"\"\"\n",
        "    Calcula o Mean Squared Error para regressÃ£o linear\n",
        "    y = ax + b\n",
        "    \"\"\"\n",
        "    predicoes = a * x_data + b\n",
        "    erro = predicoes - y_data\n",
        "    mse = np.mean(erro**2) / 2  # Dividindo por 2 para ficar mais bonito na derivada\n",
        "    return mse\n",
        "\n",
        "# Plotando os dados\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(x_data, y_data, alpha=0.7, s=50, label='Dados Observados')\n",
        "plt.plot(x_data, y_true, 'r--', label='RelaÃ§Ã£o Verdadeira (y = 2.5x + 1)')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.title('ğŸ“Š Dados para RegressÃ£o Linear')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"ğŸ“ˆ Temos {n_samples} pontos de dados\")\n",
        "print(f\"ğŸ¯ Objetivo: encontrar os melhores valores de 'a' e 'b' para y = ax + b\")\n",
        "print(f\"ğŸ’¡ Isso significa minimizar a funÃ§Ã£o J(a,b)!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando a paisagem da funÃ§Ã£o de custo\n",
        "a_range = np.linspace(1, 4, 50)\n",
        "b_range = np.linspace(-2, 4, 50)\n",
        "A, B = np.meshgrid(a_range, b_range)\n",
        "\n",
        "# Calculando o custo para cada combinaÃ§Ã£o de (a, b)\n",
        "J = np.zeros_like(A)\n",
        "for i in range(A.shape[0]):\n",
        "    for j in range(A.shape[1]):\n",
        "        J[i, j] = funcao_custo_mse(A[i, j], B[i, j], x_data, y_data)\n",
        "\n",
        "# Plotando a paisagem do erro\n",
        "fig = plt.figure(figsize=(15, 5))\n",
        "\n",
        "# GrÃ¡fico 3D\n",
        "ax1 = fig.add_subplot(131, projection='3d')\n",
        "surface = ax1.plot_surface(A, B, J, cmap='hot', alpha=0.8)\n",
        "ax1.set_xlabel('a (coef. angular)')\n",
        "ax1.set_ylabel('b (coef. linear)')\n",
        "ax1.set_zlabel('J(a,b) - Custo')\n",
        "ax1.set_title('ğŸ”ï¸ Paisagem do Erro 3D')\n",
        "\n",
        "# Curvas de nÃ­vel\n",
        "ax2 = fig.add_subplot(132)\n",
        "contour = ax2.contourf(A, B, J, levels=30, cmap='hot')\n",
        "ax2.set_xlabel('a (coef. angular)')\n",
        "ax2.set_ylabel('b (coef. linear)')\n",
        "ax2.set_title('ğŸ—ºï¸ Mapa do Erro')\n",
        "plt.colorbar(contour, ax=ax2)\n",
        "\n",
        "# Marcando o mÃ­nimo\n",
        "min_idx = np.unravel_index(np.argmin(J), J.shape)\n",
        "a_otimo = A[min_idx]\n",
        "b_otimo = B[min_idx]\n",
        "ax2.plot(a_otimo, b_otimo, 'w*', markersize=15, label=f'MÃ­nimo: ({a_otimo:.2f}, {b_otimo:.2f})')\n",
        "ax2.legend()\n",
        "\n",
        "# Comparando com a soluÃ§Ã£o verdadeira\n",
        "ax3 = fig.add_subplot(133)\n",
        "ax3.scatter(x_data, y_data, alpha=0.7, s=50, label='Dados')\n",
        "ax3.plot(x_data, y_true, 'r--', label='Verdadeiro (a=2.5, b=1.0)')\n",
        "ax3.plot(x_data, a_otimo * x_data + b_otimo, 'g-', linewidth=2, \n",
        "         label=f'Otimizado (a={a_otimo:.2f}, b={b_otimo:.2f})')\n",
        "ax3.set_xlabel('X')\n",
        "ax3.set_ylabel('Y')\n",
        "ax3.set_title('ğŸ“ˆ Resultado Final')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"ğŸ¯ Valores Ã³timos encontrados: a = {a_otimo:.2f}, b = {b_otimo:.2f}\")\n",
        "print(f\"ğŸ“Š Custo mÃ­nimo: {funcao_custo_mse(a_otimo, b_otimo, x_data, y_data):.3f}\")\n",
        "print(f\"âœ… Compare com os valores verdadeiros: a = 2.5, b = 1.0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¢ Tipos de Paisagens: Conhecendo o Terreno\n\nNem toda paisagem de erro Ã© uma tigela bonitinha como a que vimos! Na vida real, elas podem ser **BEM** mais complicadas.\n\n### Tipos Principais:\n\n1. **Convexas** (ï¿½ç¢—): TÃªm um Ãºnico mÃ­nimo global\n   - Exemplo: $f(x,y) = x^2 + y^2$\n   - **Bom**: fÃ¡ceis de otimizar\n\n2. **NÃ£o-Convexas** (ğŸ¢): MÃºltiplos mÃ­nimos locais\n   - Exemplo: $f(x,y) = sin(x) \\cdot cos(y)$\n   - **Ruim**: algoritmos podem ficar presos em mÃ­nimos locais\n\n3. **Sela** (ğŸ‡): Parece mÃ­nimo em uma direÃ§Ã£o, mÃ¡ximo em outra\n   - Exemplo: $f(x,y) = x^2 - y^2$\n   - **Complicado**: difÃ­ceis de detectar\n\n4. **PlatÃ´s** (ğŸ”ï¸): RegiÃµes \"planas\" com gradiente quase zero\n   - **Chato**: algoritmos ficam lentos\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/cÃ¡lculo-para-ia-modulo-09_img_04.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar exemplos de diferentes tipos de paisagens\n",
        "fig = plt.figure(figsize=(16, 12))\n",
        "\n",
        "# Preparando a grade\n",
        "x = np.linspace(-3, 3, 100)\n",
        "y = np.linspace(-3, 3, 100)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "\n",
        "# 1. FunÃ§Ã£o Convexa\n",
        "Z1 = X**2 + Y**2\n",
        "ax1 = fig.add_subplot(221, projection='3d')\n",
        "ax1.plot_surface(X, Y, Z1, cmap='Blues', alpha=0.8)\n",
        "ax1.set_title('ğŸ¯ Convexa: f(x,y) = xÂ² + yÂ²')\n",
        "ax1.set_xlabel('X')\n",
        "ax1.set_ylabel('Y')\n",
        "\n",
        "# 2. FunÃ§Ã£o NÃ£o-Convexa (ondulada)\n",
        "Z2 = np.sin(X) * np.cos(Y) + 0.1 * (X**2 + Y**2)\n",
        "ax2 = fig.add_subplot(222, projection='3d')\n",
        "ax2.plot_surface(X, Y, Z2, cmap='Reds', alpha=0.8)\n",
        "ax2.set_title('ğŸ¢ NÃ£o-Convexa: f(x,y) = sin(x)cos(y) + 0.1(xÂ²+yÂ²)')\n",
        "ax2.set_xlabel('X')\n",
        "ax2.set_ylabel('Y')\n",
        "\n",
        "# 3. Ponto de Sela\n",
        "Z3 = X**2 - Y**2\n",
        "ax3 = fig.add_subplot(223, projection='3d')\n",
        "ax3.plot_surface(X, Y, Z3, cmap='Greens', alpha=0.8)\n",
        "ax3.set_title('ğŸ‡ Ponto de Sela: f(x,y) = xÂ² - yÂ²')\n",
        "ax3.set_xlabel('X')\n",
        "ax3.set_ylabel('Y')\n",
        "\n",
        "# 4. FunÃ§Ã£o com PlatÃ´\n",
        "Z4 = np.tanh(X**2 + Y**2)\n",
        "ax4 = fig.add_subplot(224, projection='3d')\n",
        "ax4.plot_surface(X, Y, Z4, cmap='Purples', alpha=0.8)\n",
        "ax4.set_title('ğŸ”ï¸ Com PlatÃ´: f(x,y) = tanh(xÂ²+yÂ²)')\n",
        "ax4.set_xlabel('X')\n",
        "ax4.set_ylabel('Y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸ’¡ Cada tipo de paisagem apresenta desafios diferentes para otimizaÃ§Ã£o!\")\n",
        "print(\"ğŸ¯ No MÃ³dulo 11 vocÃª vai ver como o gradiente descendente lida com cada uma!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”¢ Mais de 2 VariÃ¡veis: Entrando na DimensÃ£o N\n\nTÃ¡, mas e quando temos **muitas** variÃ¡veis? Tipo, um modelo de deep learning pode ter **milhÃµes** de parÃ¢metros!\n\n### A MaldiÃ§Ã£o da Dimensionalidade\n\nQuando temos $n > 2$ variÃ¡veis:\n- NÃ£o conseguimos mais visualizar em 3D\n- O espaÃ§o fica **MUITO** grande\n- Pontos ficam cada vez mais esparsos\n- IntuiÃ§Ãµes 2D/3D podem nÃ£o funcionar\n\n### Exemplo: FunÃ§Ã£o de 3 VariÃ¡veis\n\n$$f(x, y, z) = x^2 + y^2 + z^2 + 2xy - z$$\n\nComo visualizar isso? **NÃ£o dÃ¡!** Mas podemos:\n1. Fixar algumas variÃ¡veis e plotar \"fatias\"\n2. Usar projeÃ§Ãµes 2D\n3. Analisar matematicamente\n4. Confiar no gradiente descendente! ğŸ˜„\n\n**Dica do Pedro**: Em deep learning, Ã© comum ter funÃ§Ãµes com milhÃµes de variÃ¡veis. A gente nÃ£o visualiza, mas usa matemÃ¡tica para navegar nessa paisagem!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo com funÃ§Ã£o de mÃºltiplas variÃ¡veis (mais de 2)\n",
        "def funcao_nd(params):\n",
        "    \"\"\"\n",
        "    FunÃ§Ã£o de n variÃ¡veis: soma dos quadrados + alguns termos cruzados\n",
        "    f(x1, x2, ..., xn) = sum(xiÂ²) + alguns termos de interaÃ§Ã£o\n",
        "    \"\"\"\n",
        "    x = np.array(params)\n",
        "    \n",
        "    # Termo quadrÃ¡tico (sempre convexo)\n",
        "    termo_quadratico = np.sum(x**2)\n",
        "    \n",
        "    # Alguns termos de interaÃ§Ã£o (tornam nÃ£o-convexa)\n",
        "    if len(x) >= 2:\n",
        "        termo_interacao = 0.5 * x[0] * x[1]\n",
        "    else:\n",
        "        termo_interacao = 0\n",
        "    \n",
        "    if len(x) >= 3:\n",
        "        termo_cubico = 0.1 * x[2]**3\n",
        "    else:\n",
        "        termo_cubico = 0\n",
        "        \n",
        "    return termo_quadratico + termo_interacao + termo_cubico\n",
        "\n",
        "# Testando com diferentes dimensÃµes\n",
        "print(\"ğŸ§ª Testando funÃ§Ã£o de mÃºltiplas variÃ¡veis:\")\n",
        "print(f\"1D: f([2]) = {funcao_nd([2]):.2f}\")\n",
        "print(f\"2D: f([1,2]) = {funcao_nd([1, 2]):.2f}\")\n",
        "print(f\"3D: f([1,2,1]) = {funcao_nd([1, 2, 1]):.2f}\")\n",
        "print(f\"5D: f([1,1,1,1,1]) = {funcao_nd([1, 1, 1, 1, 1]):.2f}\")\n",
        "print(f\"10D: f([0.5]*10) = {funcao_nd([0.5]*10):.2f}\")\n",
        "\n",
        "# Simulando um \"modelo\" com muitos parÃ¢metros\n",
        "n_params = 100\n",
        "parametros_aleatorios = np.random.normal(0, 0.1, n_params)\n",
        "custo_modelo = funcao_nd(parametros_aleatorios)\n",
        "\n",
        "print(f\"\\nğŸ¤– SimulaÃ§Ã£o de modelo com {n_params} parÃ¢metros:\")\n",
        "print(f\"   Custo atual: {custo_modelo:.4f}\")\n",
        "print(f\"   Isso Ã© uma funÃ§Ã£o de {n_params} variÃ¡veis!\")\n",
        "print(f\"   ImpossÃ­vel de visualizar, mas matemÃ¡tica funciona! ğŸ¯\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š TÃ©cnicas de VisualizaÃ§Ã£o para Altas DimensÃµes\n\nMesmo nÃ£o conseguindo plotar em 3D, existem algumas tÃ©cnicas para \"espiar\" funÃ§Ãµes de muitas variÃ¡veis:\n\n### 1. Fatias (Slicing)\nFixamos todas as variÃ¡veis exceto duas e plotamos a \"fatia\" 2D resultante.\n\n### 2. ProjeÃ§Ãµes\nEscolhemos duas direÃ§Ãµes principais e projetamos a funÃ§Ã£o nesse plano.\n\n### 3. AnimaÃ§Ãµes\nVariamos uma variÃ¡vel ao longo do tempo e observamos como a superfÃ­cie muda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TÃ©cnica de \"fatias\" para visualizar funÃ§Ã£o de 3+ variÃ¡veis\n",
        "def funcao_3d_exemplo(x, y, z):\n",
        "    \"\"\"\n",
        "    FunÃ§Ã£o de 3 variÃ¡veis para demonstraÃ§Ã£o\n",
        "    f(x,y,z) = xÂ² + yÂ² + zÂ² + xy - 2z\n",
        "    \"\"\"\n",
        "    return x**2 + y**2 + z**2 + x*y - 2*z\n",
        "\n",
        "# Criando fatias da funÃ§Ã£o 3D\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "x_range = np.linspace(-3, 3, 50)\n",
        "y_range = np.linspace(-3, 3, 50)\n",
        "X, Y = np.meshgrid(x_range, y_range)\n",
        "\n",
        "# Fatia 1: z = 0 (fixando z)\n",
        "Z1 = funcao_3d_exemplo(X, Y, 0)\n",
        "contour1 = axes[0,0].contourf(X, Y, Z1, levels=20, cmap='viridis')\n",
        "axes[0,0].set_title('ğŸ”ª Fatia: z = 0')\n",
        "axes[0,0].set_xlabel('x')\n",
        "axes[0,0].set_ylabel('y')\n",
        "plt.colorbar(contour1, ax=axes[0,0])\n",
        "\n",
        "# Fatia 2: z = 1 (fixando z em outro valor)\n",
        "Z2 = funcao_3d_exemplo(X, Y, 1)\n",
        "contour2 = axes[0,1].contourf(X, Y, Z2, levels=20, cmap='plasma')\n",
        "axes[0,1].set_title('ğŸ”ª Fatia: z = 1')\n",
        "axes[0,1].set_xlabel('x')\n",
        "axes[0,1].set_ylabel('y')\n",
        "plt.colorbar(contour2, ax=axes[0,1])\n",
        "\n",
        "# Fatia 3: y = 0 (fixando y)\n",
        "Z3 = funcao_3d_exemplo(X, 0, Y)  # Aqui Y representa z\n",
        "contour3 = axes[1,0].contourf(X, Y, Z3, levels=20, cmap='coolwarm')\n",
        "axes[1,0].set_title('ğŸ”ª Fatia: y = 0')\n",
        "axes[1,0].set_xlabel('x')\n",
        "axes[1,0].set_ylabel('z')\n",
        "plt.colorbar(contour3, ax=axes[1,0])\n",
        "\n",
        "# Fatia 4: x = 0 (fixando x)\n",
        "Z4 = funcao_3d_exemplo(0, X, Y)  # Aqui X representa y, Y representa z\n",
        "contour4 = axes[1,1].contourf(X, Y, Z4, levels=20, cmap='hot')\n",
        "axes[1,1].set_title('ğŸ”ª Fatia: x = 0')\n",
        "axes[1,1].set_xlabel('y')\n",
        "axes[1,1].set_ylabel('z')\n",
        "plt.colorbar(contour4, ax=axes[1,1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸ” Cada fatia nos mostra como a funÃ§Ã£o se comporta quando fixamos uma variÃ¡vel\")\n",
        "print(\"ğŸ“Š Isso nos ajuda a entender a estrutura da funÃ§Ã£o de 3+ dimensÃµes!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ ExercÃ­cio PrÃ¡tico 1: Explorando Sua PrÃ³pria Paisagem\n\nAgora Ã© sua vez! Vamos criar e explorar uma funÃ§Ã£o personalizada.\n\n**Desafio**: \n1. Crie uma funÃ§Ã£o de duas variÃ¡veis interessante\n2. Plote ela em 3D e com curvas de nÃ­vel\n3. Identifique onde estÃ£o os mÃ­nimos e mÃ¡ximos\n4. Analise o comportamento da funÃ§Ã£o\n\n**Algumas sugestÃµes de funÃ§Ãµes para testar**:\n- $f(x,y) = x^4 + y^4 - 4xy$\n- $f(x,y) = e^{-(x^2+y^2)} \\cos(3x) \\sin(3y)$\n- $f(x,y) = (x^2 + y^2 - 1)^2 + x^2$\n- **Ou invente a sua!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ‹ï¸â€â™‚ï¸ EXERCÃCIO 1 - Complete o cÃ³digo abaixo!\n",
        "\n",
        "def minha_funcao(x, y):\n",
        "    \"\"\"\n",
        "    Defina sua funÃ§Ã£o aqui!\n",
        "    Exemplo: return x**4 + y**4 - 4*x*y\n",
        "    \"\"\"\n",
        "    # TODO: Implemente sua funÃ§Ã£o aqui\n",
        "    return x**2 + y**2  # Substitua por algo mais interessante!\n",
        "\n",
        "# Criando a grade\n",
        "x = np.linspace(-3, 3, 100)\n",
        "y = np.linspace(-3, 3, 100)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "Z = minha_funcao(X, Y)\n",
        "\n",
        "# TODO: Crie visualizaÃ§Ãµes da sua funÃ§Ã£o\n",
        "# Dicas:\n",
        "# 1. Use fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
        "# 2. FaÃ§a um grÃ¡fico 3D e um de curvas de nÃ­vel\n",
        "# 3. Analise os resultados!\n",
        "\n",
        "fig = plt.figure(figsize=(15, 6))\n",
        "\n",
        "# GrÃ¡fico 3D\n",
        "ax1 = fig.add_subplot(121, projection='3d')\n",
        "# TODO: Complete aqui\n",
        "\n",
        "# Curvas de nÃ­vel\n",
        "ax2 = fig.add_subplot(122)\n",
        "# TODO: Complete aqui\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# TODO: Analise sua funÃ§Ã£o\n",
        "print(\"ğŸ“Š AnÃ¡lise da minha funÃ§Ã£o:\")\n",
        "print(\"   - Tipo de paisagem: \")\n",
        "print(\"   - Pontos interessantes: \")\n",
        "print(\"   - Comportamento geral: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸš€ Preparando para o PrÃ³ximo NÃ­vel: Derivadas Parciais\n\nBom pessoal, agora que vocÃªs jÃ¡ entendem o que sÃ£o funÃ§Ãµes de mÃºltiplas variÃ¡veis e como elas criam essas paisagens 3D incrÃ­veis, tÃ¡ na hora de falar sobre o **prÃ³ximo passo**!\n\n### O Problema da NavegaÃ§Ã£o\n\nImaginem que vocÃªs estÃ£o perdidos nessa paisagem montanhosa. Como vocÃªs saberiam:\n- **Para onde ir** para descer mais rÃ¡pido?\n- **Qual direÃ§Ã£o** leva ao vale mais profundo?\n- **QuÃ£o Ã­ngreme** estÃ¡ o terreno em cada direÃ§Ã£o?\n\n### A ConexÃ£o com IA\n\nLembrem do **MÃ³dulo 6** sobre a Regra da Cadeia? LÃ¡ vocÃªs viram como calcular derivadas de funÃ§Ãµes compostas. Agora vamos expandir isso!\n\nNo **MÃ³dulo 10**, vocÃªs vÃ£o aprender sobre:\n- **Derivadas Parciais**: como calcular a \"inclinaÃ§Ã£o\" em cada direÃ§Ã£o\n- **Gradiente**: o vetor que aponta na direÃ§Ã£o de maior crescimento\n- **Como isso se conecta** com o backpropagation em redes neurais\n\n```mermaid\ngraph LR\n    A[FunÃ§Ãµes MÃºltiplas VariÃ¡veis] --> B[Derivadas Parciais]\n    B --> C[Gradiente]\n    C --> D[Gradiente Descendente]\n    D --> E[OtimizaÃ§Ã£o de Modelos]\n```\n\n**Dica do Pedro**: Tudo que vocÃªs viram hoje Ã© a **base** para entender como os algoritmos de otimizaÃ§Ã£o funcionam. Sem entender a paisagem, nÃ£o dÃ¡ para navegar nela!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uma pequena prÃ©via do que vem por aÃ­...\n",
        "def preview_gradiente_descendente():\n",
        "    \"\"\"\n",
        "    Uma pequena demonstraÃ§Ã£o de como o gradiente descendente \n",
        "    navega na paisagem de erro\n",
        "    \"\"\"\n",
        "    print(\"ğŸ”® PrÃ©via do MÃ³dulo 11 - Gradiente Descendente:\")\n",
        "    print(\"\\n   ğŸ§­ O algoritmo vai:\")\n",
        "    print(\"   1. Calcular a derivada parcial em relaÃ§Ã£o a cada variÃ¡vel\")\n",
        "    print(\"   2. Formar o vetor gradiente\")\n",
        "    print(\"   3. Dar um passo na direÃ§Ã£o OPOSTA ao gradiente\")\n",
        "    print(\"   4. Repetir atÃ© encontrar o mÃ­nimo\")\n",
        "    \n",
        "    print(\"\\n   ğŸ“ Matematicamente:\")\n",
        "    print(\"   âˆ‡f(x,y) = [âˆ‚f/âˆ‚x, âˆ‚f/âˆ‚y]  <- Isso Ã© o gradiente\")\n",
        "    print(\"   x_novo = x_antigo - Î± * âˆ‚f/âˆ‚x  <- Passo de otimizaÃ§Ã£o\")\n",
        "    print(\"   y_novo = y_antigo - Î± * âˆ‚f/âˆ‚y\")\n",
        "    \n",
        "    # SimulaÃ§Ã£o simples\n",
        "    x_atual, y_atual = 2.0, 2.0  # Ponto inicial\n",
        "    alpha = 0.1  # Taxa de aprendizado\n",
        "    \n",
        "    print(f\"\\n   ğŸ¯ SimulaÃ§Ã£o (f(x,y) = xÂ² + yÂ²):\")\n",
        "    print(f\"   PosiÃ§Ã£o inicial: ({x_atual:.2f}, {y_atual:.2f})\")\n",
        "    \n",
        "    for i in range(3):\n",
        "        # Derivadas parciais de f(x,y) = xÂ² + yÂ²\n",
        "        grad_x = 2 * x_atual  # âˆ‚f/âˆ‚x = 2x\n",
        "        grad_y = 2 * y_atual  # âˆ‚f/âˆ‚y = 2y\n",
        "        \n",
        "        # Passo do gradiente descendente\n",
        "        x_atual = x_atual - alpha * grad_x\n",
        "        y_atual = y_atual - alpha * grad_y\n",
        "        \n",
        "        custo = x_atual**2 + y_atual**2\n",
        "        print(f\"   Passo {i+1}: ({x_atual:.2f}, {y_atual:.2f}) | Custo: {custo:.3f}\")\n",
        "    \n",
        "    print(\"\\n   ğŸš€ EstÃ¡ descendo em direÃ§Ã£o ao mÃ­nimo (0,0)!\")\n",
        "    print(\"   ğŸ“š Nos prÃ³ximos mÃ³dulos vocÃª vai entender isso a fundo!\")\n",
        "\n",
        "preview_gradiente_descendente()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ ExercÃ­cio PrÃ¡tico 2: Modelagem de um Problema Real\n\nVamos aplicar tudo que aprendemos em um problema mais realista!\n\n**CenÃ¡rio**: VocÃª trabalha em uma startup de delivery e quer otimizar o tempo de entrega baseado em duas variÃ¡veis:\n- $x$: NÃºmero de entregadores\n- $y$: NÃºmero de pontos de distribuiÃ§Ã£o\n\n**FunÃ§Ã£o de Custo**: \n$$C(x,y) = \\frac{1000}{x} + \\frac{500}{y} + 10x + 20y + 0.5xy$$\n\nOnde:\n- $\\frac{1000}{x}$: Custo por falta de entregadores\n- $\\frac{500}{y}$: Custo por falta de pontos de distribuiÃ§Ã£o  \n- $10x + 20y$: Custos operacionais\n- $0.5xy$: Custo de coordenaÃ§Ã£o\n\n**Desafio**: Encontre a combinaÃ§Ã£o Ã³tima de entregadores e pontos de distribuiÃ§Ã£o!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ‹ï¸â€â™‚ï¸ EXERCÃCIO 2 - Problema Real de OtimizaÃ§Ã£o\n",
        "\n",
        "def custo_delivery(x, y):\n",
        "    \"\"\"\n",
        "    FunÃ§Ã£o de custo para o sistema de delivery\n",
        "    x: nÃºmero de entregadores\n",
        "    y: nÃºmero de pontos de distribuiÃ§Ã£o\n",
        "    \"\"\"\n",
        "    if x <= 0 or y <= 0:\n",
        "        return float('inf')  # Custo infinito se nÃ£o tem recursos\n",
        "    \n",
        "    custo_falta_entregadores = 1000 / x\n",
        "    custo_falta_pontos = 500 / y\n",
        "    custo_operacional = 10 * x + 20 * y\n",
        "    custo_coordenacao = 0.5 * x * y\n",
        "    \n",
        "    return custo_falta_entregadores + custo_falta_pontos + custo_operacional + custo_coordenacao\n",
        "\n",
        "# TODO: Complete a anÃ¡lise do problema\n",
        "\n",
        "# 1. Criar grade de valores realistas\n",
        "x_entregadores = np.linspace(1, 50, 100)  # 1 a 50 entregadores\n",
        "y_pontos = np.linspace(1, 20, 100)       # 1 a 20 pontos\n",
        "X, Y = np.meshgrid(x_entregadores, y_pontos)\n",
        "\n",
        "# TODO: Calcule a matriz de custos Z\n",
        "Z = np.zeros_like(X)\n",
        "for i in range(X.shape[0]):\n",
        "    for j in range(X.shape[1]):\n",
        "        Z[i, j] = custo_delivery(X[i, j], Y[i, j])\n",
        "\n",
        "# TODO: Encontre o mÃ­nimo\n",
        "min_idx = np.unravel_index(np.argmin(Z), Z.shape)\n",
        "x_otimo = X[min_idx]\n",
        "y_otimo = Y[min_idx]\n",
        "custo_minimo = Z[min_idx]\n",
        "\n",
        "# TODO: Crie visualizaÃ§Ãµes\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Curvas de nÃ­vel\n",
        "contour = ax1.contourf(X, Y, Z, levels=30, cmap='hot')\n",
        "ax1.contour(X, Y, Z, levels=30, colors='white', alpha=0.3, linewidths=0.5)\n",
        "ax1.plot(x_otimo, y_otimo, 'w*', markersize=15, label=f'Ã“timo: ({x_otimo:.1f}, {y_otimo:.1f})')\n",
        "ax1.set_xlabel('NÃºmero de Entregadores')\n",
        "ax1.set_ylabel('NÃºmero de Pontos de DistribuiÃ§Ã£o')\n",
        "ax1.set_title('ğŸšš Mapa de Custo do Delivery')\n",
        "ax1.legend()\n",
        "plt.colorbar(contour, ax=ax1)\n",
        "\n",
        "# GrÃ¡fico 3D\n",
        "ax2 = fig.add_subplot(122, projection='3d')\n",
        "surface = ax2.plot_surface(X, Y, Z, cmap='hot', alpha=0.7)\n",
        "ax2.scatter(x_otimo, y_otimo, custo_minimo, color='white', s=100, label='MÃ­nimo')\n",
        "ax2.set_xlabel('Entregadores')\n",
        "ax2.set_ylabel('Pontos')\n",
        "ax2.set_zlabel('Custo Total')\n",
        "ax2.set_title('ğŸ”ï¸ Paisagem de Custo 3D')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# TODO: Analise os resultados\n",
        "print(\"ğŸ“Š RESULTADOS DA OTIMIZAÃ‡ÃƒO:\")\n",
        "print(f\"   ğŸ¯ NÃºmero Ã³timo de entregadores: {x_otimo:.1f}\")\n",
        "print(f\"   ğŸ¯ NÃºmero Ã³timo de pontos: {y_otimo:.1f}\")\n",
        "print(f\"   ğŸ’° Custo mÃ­nimo: R$ {custo_minimo:.2f}\")\n",
        "\n",
        "print(f\"\\nğŸ’¡ INTERPRETAÃ‡ÃƒO:\")\n",
        "print(f\"   - Com poucos entregadores: custo explode por falta de pessoal\")\n",
        "print(f\"   - Com muitos entregadores: custo operacional fica alto\")\n",
        "print(f\"   - O ponto Ã³timo equilibra esses trade-offs!\")\n",
        "\n",
        "# TODO: Teste diferentes cenÃ¡rios\n",
        "print(f\"\\nğŸ§ª TESTE DE CENÃRIOS:\")\n",
        "cenarios = [(10, 5), (20, 10), (30, 15), (40, 5)]\n",
        "for x_test, y_test in cenarios:\n",
        "    custo_test = custo_delivery(x_test, y_test)\n",
        "    print(f\"   CenÃ¡rio ({x_test} entregadores, {y_test} pontos): R$ {custo_test:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ Resumo do MÃ³dulo: O que Aprendemos?\n\n**ParabÃ©ns!** VocÃªs acabaram de dar um **mega** passo no entendimento de como a IA realmente funciona por baixo do capÃ´!\n\n### ğŸ¯ Conceitos Principais:\n\n1. **FunÃ§Ãµes de MÃºltiplas VariÃ¡veis**\n   - $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$\n   - MÃºltiplas entradas, uma saÃ­da\n   - Base dos modelos de ML\n\n2. **VisualizaÃ§Ã£o da Paisagem**\n   - GrÃ¡ficos 3D para 2 variÃ¡veis\n   - Curvas de nÃ­vel como \"mapas topogrÃ¡ficos\"\n   - TÃ©cnicas de fatias para 3+ dimensÃµes\n\n3. **Tipos de Paisagens**\n   - Convexas (fÃ¡ceis) ğŸ¯\n   - NÃ£o-convexas (difÃ­ceis) ğŸ¢\n   - Pontos de sela (traiÃ§oeiros) ğŸ‡\n   - PlatÃ´s (chatos) ğŸ”ï¸\n\n4. **ConexÃ£o com IA**\n   - FunÃ§Ãµes de custo sÃ£o funÃ§Ãµes de mÃºltiplas variÃ¡veis\n   - ParÃ¢metros do modelo = variÃ¡veis da funÃ§Ã£o\n   - OtimizaÃ§Ã£o = navegaÃ§Ã£o na paisagem\n\n### ğŸš€ PrÃ³ximos Passos:\n\n- **MÃ³dulo 10**: Derivadas Parciais e Gradientes (a bÃºssola!)\n- **MÃ³dulo 11**: Gradiente Descendente (a navegaÃ§Ã£o!)\n- **MÃ³dulo 12**: VariaÃ§Ãµes e truques avanÃ§ados\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/cÃ¡lculo-para-ia-modulo-09_img_05.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ‰ ParabÃ©ns! Vamos celebrar o que aprendemos!\n",
        "\n",
        "def celebrar_aprendizado():\n",
        "    print(\"ğŸŠ PARABÃ‰NS! VocÃª completou o MÃ³dulo 9! ğŸŠ\\n\")\n",
        "    \n",
        "    conceitos_dominados = [\n",
        "        \"âœ… FunÃ§Ãµes de mÃºltiplas variÃ¡veis\",\n",
        "        \"âœ… VisualizaÃ§Ã£o 3D de paisagens de erro\", \n",
        "        \"âœ… Curvas de nÃ­vel e mapas topogrÃ¡ficos\",\n",
        "        \"âœ… Diferentes tipos de paisagens\",\n",
        "        \"âœ… ConexÃ£o com funÃ§Ãµes de custo em IA\",\n",
        "        \"âœ… TÃ©cnicas para altas dimensÃµes\",\n",
        "        \"âœ… Modelagem de problemas reais\"\n",
        "    ]\n",
        "    \n",
        "    print(\"ğŸ“š CONCEITOS DOMINADOS:\")\n",
        "    for conceito in conceitos_dominados:\n",
        "        print(f\"   {conceito}\")\n",
        "    \n",
        "    print(\"\\nğŸ¯ PRÃ“XIMA AVENTURA:\")\n",
        "    print(\"   ğŸ“ MÃ³dulo 10: Derivadas Parciais e Gradientes\")\n",
        "    print(\"   ğŸ§­ VocÃª vai aprender a navegar nessas paisagens!\")\n",
        "    \n",
        "    print(\"\\nğŸ’ª DICA FINAL DO PEDRO:\")\n",
        "    print(\"   'Agora vocÃªs jÃ¡ conseguem VER a paisagem do erro.'\")\n",
        "    print(\"   'No prÃ³ximo mÃ³dulo vamos aprender a NAVEGAR nela!'\")\n",
        "    print(\"   'Cada passo que vocÃªs dÃ£o Ã© um passo mais perto de\")\n",
        "    print(\"    dominar a matemÃ¡tica por trÃ¡s da IA! ğŸš€'\")\n",
        "    \n",
        "    # Uma pequena arte ASCII para celebrar\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"    ğŸ”ï¸  VOCÃŠ CONQUISTOU A PAISAGEM!  ğŸ”ï¸\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "celebrar_aprendizado()\n",
        "\n",
        "# EstatÃ­sticas do notebook\n",
        "print(\"\\nğŸ“Š ESTATÃSTICAS DO NOTEBOOK:\")\n",
        "print(f\"   ğŸ”¢ FunÃ§Ãµes criadas: 8+\")\n",
        "print(f\"   ğŸ“ˆ GrÃ¡ficos gerados: 10+\")\n",
        "print(f\"   ğŸ§® ExercÃ­cios prÃ¡ticos: 2\")\n",
        "print(f\"   ğŸ’¡ Dicas do Pedro: VÃ¡rias!\")\n",
        "print(f\"   ğŸ¯ NÃ­vel de diversÃ£o: MÃXIMO! ğŸ˜„\")"
      ]
    }
  ]
}